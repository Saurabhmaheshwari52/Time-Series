{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(15, 5))\n",
    "from timeit import default_timer as timer\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Reshape, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test(test):\n",
    "    test = test.loc[(test['shop_id'].isin(sales_test['shop_id']))&(test['item_id'].isin(sales_test['item_id'])),:].copy()\n",
    "    test_pred = test['cnt_shop_item'].copy()\n",
    "    test.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "    return(test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_sets2(months, data):\n",
    "    X_train = data.loc[~data['date_block_num'].isin(months+[34]),:].drop('cnt_shop_item', axis=1)\n",
    "    X_val = data.loc[data['date_block_num'].isin(months),:]\n",
    "    X_val, y_val = create_test(X_val)\n",
    "    X_test = data.loc[data['date_block_num'] == 34,:].drop('cnt_shop_item',axis=1)\n",
    "    y_train = data.loc[~data['date_block_num'].isin(months+[34]),'cnt_shop_item']\n",
    "    return(dict({'train': X_train, 'val': X_val, 'test': X_test, 'train_y': y_train, 'val_y': y_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"full_data_2.pkl\", \"rb\") as input_file:\n",
    "    full_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cat = create_cv_sets2([9,21,33], full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = [i for i in dict_cat['train'].columns.tolist() if i not in ['date_block_num', 'shop_id', 'item_id', \n",
    "                                                                      'item_category_id', 'month', 'year']]\n",
    "for feat in n_feats:\n",
    "    scaler = StandardScaler()\n",
    "    dict_cat['train'][feat] = scaler.fit_transform(dict_cat['train'][feat].values.reshape(-1,1))\n",
    "    dict_cat['val'][feat] = scaler.transform(dict_cat['val'][feat].values.reshape(-1,1))\n",
    "    dict_cat['test'][feat] = scaler.transform(dict_cat['test'][feat].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_of_var = [\n",
    "    'date_block_num',\n",
    "    \n",
    "    'shop_id_enc_cnt_shop_item', 'shop_id_enc_cnt_shop',\n",
    "    'shop_id_enc_cnt_item', 'shop_id_enc_cnt_itcat',\n",
    "    \n",
    "    'item_id_enc_cnt_shop_item', 'item_id_enc_cnt_shop',\n",
    "    'item_id_enc_cnt_item', 'item_id_enc_cnt_itcat',\n",
    "    \n",
    "    'item_category_id_enc_cnt_shop_item', 'item_category_id_enc_cnt_shop',\n",
    "    'item_category_id_enc_cnt_item', 'item_category_id_enc_cnt_itcat',\n",
    "    \n",
    "    'month_enc_cnt_shop_item', 'month_enc_cnt_shop', \n",
    "    'month_enc_cnt_item', 'month_enc_cnt_itcat', \n",
    "    \n",
    "    'year_enc_cnt_shop_item', 'year_enc_cnt_shop',\n",
    "    'year_enc_cnt_item', 'year_enc_cnt_itcat',\n",
    "    \n",
    "    'sales_shop_item_lag_1', 'price_shop_item_lag_1', \n",
    "    'sales_shop_item_lag_2', 'price_shop_item_lag_2',\n",
    "    'cnt_shop_item_lag_1', 'cnt_shop_item_lag_2',\n",
    "    'cnt_shop_item_lag_3', 'cnt_shop_item_lag_4',\n",
    "    'cnt_shop_item_lag_5', 'cnt_shop_item_lag_6',\n",
    "    'cnt_shop_item_lag_12',\n",
    "    \n",
    "    'sales_shop_lag_1', 'price_shop_lag_1',\n",
    "    'sales_shop_lag_2', 'price_shop_lag_2',\n",
    "    'cnt_shop_lag_1', 'cnt_shop_lag_2',\n",
    "    'cnt_shop_lag_3', 'cnt_shop_lag_4',\n",
    "    'cnt_shop_lag_5', 'cnt_shop_lag_6',\n",
    "    'cnt_shop_lag_12',\n",
    "    \n",
    "    'sales_item_lag_1', 'price_item_lag_1', \n",
    "    'sales_item_lag_2', 'price_item_lag_2',\n",
    "    'cnt_item_lag_1', 'cnt_item_lag_2',\n",
    "    'cnt_item_lag_3', 'cnt_item_lag_4',\n",
    "    'cnt_item_lag_5', 'cnt_item_lag_6',\n",
    "    'cnt_item_lag_12',\n",
    "    \n",
    "    'sales_itcat_lag_1', 'price_itcat_lag_1', \n",
    "    'sales_itcat_lag_2', 'price_itcat_lag_2',\n",
    "    'cnt_itcat_lag_1', 'cnt_itcat_lag_2',\n",
    "    'cnt_itcat_lag_3', 'cnt_itcat_lag_4',\n",
    "    'cnt_itcat_lag_5', 'cnt_itcat_lag_6',\n",
    "    'cnt_itcat_lag_12',\n",
    "    \n",
    "    'item_name_1', 'item_name_2', \n",
    "    'item_name_3', 'item_name_4', \n",
    "    'item_name_5', \n",
    "    \n",
    "    'item_category_name_1', 'item_category_name_2', \n",
    "    'item_category_name_3', 'item_category_name_4',\n",
    "    'item_category_name_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_of_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_df(mat):\n",
    "    df = mat.copy()\n",
    "    df['month']-=1\n",
    "    df['year']-=2013\n",
    "    X = []\n",
    "    cat_ind = ['shop_id', 'item_id', 'item_category_id', 'month', 'year']\n",
    "    for feat in cat_ind:\n",
    "        X.append(df[feat].values)\n",
    "    df = df.drop(cat_ind, axis = 1)\n",
    "    freq_cat = [1,4,4,4,4,4,11,11,11,11,5,5]\n",
    "    curr = 0\n",
    "    for i in freq_cat:\n",
    "        X.append(df.iloc[:,curr:(curr+i)].values)\n",
    "        curr+=i\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dict = dict()\n",
    "for key in dict_cat.keys():\n",
    "    nn_dict[key] = create_emb_df(dict_cat[key]) if 'y' not in key else dict_cat[key].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  0,  0, ..., 59, 59, 59]),\n",
       " array([   32,    33,    35, ..., 22091, 22100, 22139]),\n",
       " array([40, 37, 40, ..., 83, 42, 38]),\n",
       " array([0, 0, 0, ..., 8, 8, 8]),\n",
       " array([0, 0, 0, ..., 2, 2, 2]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [32],\n",
       "        [32],\n",
       "        [32]]),\n",
       " array([[-6.2345533e+00, -1.3888444e+00, -2.9114616e+00, -4.9000564e+00],\n",
       "        [ 2.9323049e+00, -3.4674257e-01,  4.3985415e+00,  1.9888057e+00],\n",
       "        [ 2.9323049e+00,  6.2474667e-04,  2.9560995e+00,  5.2822995e-01],\n",
       "        ...,\n",
       "        [-5.8465254e-01, -8.1212723e-01,  9.6533239e-01, -7.9759121e-01],\n",
       "        [-5.8450937e-01, -8.1213677e-01,  9.6526039e-01, -7.9775351e-01],\n",
       "        [-5.8461505e-01, -8.1214637e-01,  9.6528953e-01, -7.9790860e-01]],\n",
       "       dtype=float32),\n",
       " array([[-1.1109886 , -3.43888   , -0.33035722, -1.1009835 ],\n",
       "        [-1.1109886 , -3.43888   , -0.33035722, -1.1009835 ],\n",
       "        [-1.1109886 , -3.43888   , -0.33035722, -1.1009835 ],\n",
       "        ...,\n",
       "        [ 0.16370453, -0.56705487, -0.15512955, -1.0524142 ],\n",
       "        [ 0.1921835 , -1.5481133 , -0.00513399, -1.0399189 ],\n",
       "        [-0.5509986 ,  0.25921375, -0.2736332 , -0.9477257 ]],\n",
       "       dtype=float32),\n",
       " array([[-2.0634117 , -6.5296702 , -0.33076963, -1.1201726 ],\n",
       "        [-2.0634117 , -6.5296702 , -0.33076963, -1.1201726 ],\n",
       "        [ 0.9073376 , -1.5835302 ,  0.4550825 ,  0.5163421 ],\n",
       "        ...,\n",
       "        [ 2.63533   , -2.0149975 ,  0.30105126, -1.0771133 ],\n",
       "        [ 1.3016849 , -3.2559702 ,  0.33120832, -1.0629447 ],\n",
       "        [-0.61234117, -0.4228732 , -0.18910381, -0.98203784]],\n",
       "       dtype=float32),\n",
       " array([[-11.703648  ,  -4.3626833 ,  -4.22833   ,  -6.12771   ],\n",
       "        [  5.798015  ,  -0.8799174 ,   5.848124  ,   2.601422  ],\n",
       "        [  5.798015  ,   0.28100467,   3.8597934 ,   0.7506725 ],\n",
       "        ...,\n",
       "        [  0.26077473,  -0.3198615 ,   0.2653817 ,  -1.976351  ],\n",
       "        [  0.26082063,  -0.31988528,   0.26536834,  -1.9763838 ],\n",
       "        [  0.26077056,  -0.31990907,   0.26538324,  -1.9764149 ]],\n",
       "       dtype=float32),\n",
       " array([[-33.394382 ,  -6.168216 , -11.437751 ,  -2.9495459],\n",
       "        [ 16.789425 ,  -0.9749353,  18.566141 ,   1.851836 ],\n",
       "        [ 16.789425 ,   0.7561585,  12.64564  ,   0.8338476],\n",
       "        ...,\n",
       "        [ -1.5126885,  -1.6223001,  -1.6677797,  -1.5576676],\n",
       "        [ -1.5126327,  -1.6223092,  -1.6677828,  -1.5576717],\n",
       "        [ -1.5126785,  -1.6223179,  -1.6677544,  -1.5576754]],\n",
       "       dtype=float32),\n",
       " array([[-0.09911203, -0.33088225, -0.60123104, ..., -0.09009894,\n",
       "         -0.31007972, -0.54761946],\n",
       "        [-0.09911203, -0.33088225, -0.60123104, ..., -0.09009894,\n",
       "         -0.31007972, -0.54761946],\n",
       "        [-0.09911203, -0.33088225, -0.60123104, ..., -0.09009894,\n",
       "         -0.31007972, -0.54761946],\n",
       "        ...,\n",
       "        [-0.09911203, -0.33088225, -0.60123104, ..., -0.09009894,\n",
       "         -0.31007972, -0.54761946],\n",
       "        [-0.09911203, -0.33088225, -0.60123104, ..., -0.09009894,\n",
       "         -0.31007972, -0.54761946],\n",
       "        [-0.09911203, -0.33088225, -0.60123104, ..., -0.09009894,\n",
       "         -0.31007972, -0.54761946]], dtype=float32),\n",
       " array([[-0.7101644 , -0.09356915, -0.3106123 , ..., -0.5488871 ,\n",
       "         -0.41475275, -0.54880685],\n",
       "        [-0.7101644 , -0.09356915, -0.3106123 , ..., -0.5488871 ,\n",
       "         -0.41475275, -0.54880685],\n",
       "        [-0.7101644 , -0.09356915, -0.3106123 , ..., -0.5488871 ,\n",
       "         -0.41475275, -0.54880685],\n",
       "        ...,\n",
       "        [-0.7101644 , -0.09356915, -0.3106123 , ..., -0.5488871 ,\n",
       "         -0.41475275, -0.54880685],\n",
       "        [-0.7101644 , -0.09356915, -0.3106123 , ..., -0.5488871 ,\n",
       "         -0.41475275, -0.54880685],\n",
       "        [-0.7101644 , -0.09356915, -0.3106123 , ..., -0.5488871 ,\n",
       "         -0.41475275, -0.54880685]], dtype=float32),\n",
       " array([[-0.16508345, -0.50010383, -0.3835294 , ..., -0.14079535,\n",
       "         -0.432958  , -0.3390006 ],\n",
       "        [-0.16508345, -0.50010383, -0.3835294 , ..., -0.14079535,\n",
       "         -0.432958  , -0.3390006 ],\n",
       "        [-0.16508345, -0.50010383, -0.3835294 , ..., -0.14079535,\n",
       "         -0.432958  , -0.3390006 ],\n",
       "        ...,\n",
       "        [-0.16508345, -0.50010383, -0.3835294 , ..., -0.14079535,\n",
       "         -0.432958  , -0.3390006 ],\n",
       "        [-0.16508345, -0.50010383, -0.3835294 , ..., -0.14079535,\n",
       "         -0.432958  , -0.3390006 ],\n",
       "        [-0.16508345, -0.50010383, -0.3835294 , ..., -0.14079535,\n",
       "         -0.432958  , -0.3390006 ]], dtype=float32),\n",
       " array([[-0.4444048 , -0.13020507, -0.40783614, ..., -0.2934901 ,\n",
       "         -0.08902115, -0.27155557],\n",
       "        [-0.4444048 , -0.13020507, -0.40783614, ..., -0.2934901 ,\n",
       "         -0.08902115, -0.27155557],\n",
       "        [-0.4444048 , -0.13020507, -0.40783614, ..., -0.2934901 ,\n",
       "         -0.08902115, -0.27155557],\n",
       "        ...,\n",
       "        [-0.4444048 , -0.13020507, -0.40783614, ...,  0.37233126,\n",
       "          0.11086101, -0.21559839],\n",
       "        [-0.4444048 , -0.13020507, -0.40783614, ..., -0.2934901 ,\n",
       "         -0.08902115, -0.27155557],\n",
       "        [-0.4444048 , -0.13020507, -0.40783614, ..., -0.2934901 ,\n",
       "         -0.08902115, -0.27155557]], dtype=float32),\n",
       " array([[-0.6323707 , -0.36986554, -0.2737662 , -0.43395734, -0.31925195],\n",
       "        [-0.4769186 ,  9.595512  , -1.3024358 , -0.49040517, -1.0468707 ],\n",
       "        [-0.543616  , -0.32112053, -0.12353646, -0.52044696, -0.25944284],\n",
       "        ...,\n",
       "        [-0.6289329 , -0.36340675, -0.26329717, -0.43725637, -0.31562   ],\n",
       "        [-0.5848284 , -0.36611792, -0.2497024 , -0.42506102, -0.30525988],\n",
       "        [-0.5029283 ,  4.5897045 , -0.7913471 , -0.3494743 , -0.6554247 ]],\n",
       "       dtype=float32),\n",
       " array([[-0.7339705 , -0.26655403,  0.4201117 ,  0.8017097 , -0.08415405],\n",
       "        [-0.7167041 , -0.21773186,  0.34199363,  1.0861423 ,  0.03914746],\n",
       "        [-0.7339705 , -0.26655403,  0.4201117 ,  0.8017097 , -0.08415405],\n",
       "        ...,\n",
       "        [-0.8696037 , -0.5059838 ,  0.6859744 ,  0.17076132, -0.31570083],\n",
       "        [-0.52565455,  1.6527098 ,  2.4854906 , -0.8553037 , -0.338694  ],\n",
       "        [-0.73687893, -0.25324053,  0.38087767,  0.996068  ,  0.00633348]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_dict['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dense embedding neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dense():\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    shop_id_in = Input((1,), name = 'shop_id_in')\n",
    "    shop_id = Embedding(60,12)(shop_id_in)\n",
    "    shop_id = Reshape((12,))(shop_id)\n",
    "    layers.append(shop_id)\n",
    "    \n",
    "    item_id_in = Input((1,), name='item_id_in')\n",
    "    item_id = Embedding(22170,20)(item_id_in)\n",
    "    item_id = Reshape((20,))(item_id)\n",
    "    layers.append(item_id)\n",
    "    \n",
    "    itcat_id_in = Input((1,), name='itcat_in')\n",
    "    itcat_id = Embedding(84,12)(itcat_id_in)\n",
    "    itcat_id = Reshape((12,))(itcat_id)\n",
    "    layers.append(itcat_id)\n",
    "    \n",
    "    month_in = Input((1,), name='month_in')\n",
    "    month = Embedding(12,4)(month_in)\n",
    "    month = Reshape((4,))(month)\n",
    "    layers.append(month)\n",
    "    \n",
    "    year_in = Input((1,), name='year_in')\n",
    "    year = Embedding(3,2)(year_in)\n",
    "    year = Reshape((2,))(year)\n",
    "    layers.append(year)\n",
    "    \n",
    "    date_block_in = Input((1,), name='date_block_in')\n",
    "    date_block = Dense(1)(date_block_in)\n",
    "    layers.append(date_block)\n",
    "    \n",
    "    shop_id_enc_in = Input((4,), name='shop_id_end_in')\n",
    "    shop_id_enc = Dense(4)(shop_id_enc_in)\n",
    "    layers.append(shop_id_enc)\n",
    "    \n",
    "    item_id_enc_in = Input((4,), name='item_id_end_in')\n",
    "    item_id_enc = Dense(4)(item_id_enc_in)\n",
    "    layers.append(item_id_enc)\n",
    "    \n",
    "    itcat_id_enc_in = Input((4,), name='itcat_id_end_in')\n",
    "    itcat_id_enc = Dense(4)(itcat_id_enc_in)\n",
    "    layers.append(itcat_id_enc)\n",
    "    \n",
    "    month_id_enc_in = Input((4,), name='month_id_end_in')\n",
    "    month_id_enc = Dense(4)(month_id_enc_in)\n",
    "    layers.append(month_id_enc)\n",
    "    \n",
    "    year_id_enc_in = Input((4,), name='year_id_end_in')\n",
    "    year_id_enc = Dense(4)(year_id_enc_in)\n",
    "    layers.append(year_id_enc)\n",
    "    \n",
    "    shop_item_lag_in = Input((11,), name='shop_item_lag_in')\n",
    "    shop_item_lag = Dense(11)(shop_item_lag_in)\n",
    "    layers.append(shop_item_lag)\n",
    "    \n",
    "    shop_lag_in = Input((11,), name='shop_lag_in')\n",
    "    shop_lag = Dense(11)(shop_lag_in)\n",
    "    layers.append(shop_lag)\n",
    "    \n",
    "    item_lag_in = Input((11,), name='item_lag_in')\n",
    "    item_lag = Dense(11)(item_lag_in)\n",
    "    layers.append(item_lag)\n",
    "    \n",
    "    itcat_lag_in = Input((11,), name='itcat_lag_in')\n",
    "    itcat_lag = Dense(11)(itcat_lag_in)\n",
    "    layers.append(itcat_lag)\n",
    "    \n",
    "    item_name_in = Input((5,),name='item_name_in')\n",
    "    item_name = Dense(5)(item_name_in)\n",
    "    layers.append(item_name)\n",
    "    \n",
    "    itcat_name_in = Input((5,), name='itcat_name_in')\n",
    "    itcat_name = Dense(5)(itcat_name_in)\n",
    "    layers.append(itcat_name)\n",
    "    \n",
    "    model = Concatenate()(layers)\n",
    "    model = Dense(1000, activation='relu',name='fc1')(model)\n",
    "    model = Dropout(0.3)(model)\n",
    "    \n",
    "    model = Dense(500, activation='relu', name='fc2')(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "    \n",
    "    model = Dense(150,activation='relu', name='fc3')(model)\n",
    "    model = Dropout(0.1)(model)\n",
    "    \n",
    "    model = Dense(15, activation='relu',name='fc4')(model)\n",
    "    model= Dense(1,name='fc5')(model)\n",
    "    \n",
    "    final_model = Model(inputs = [shop_id_in, item_id_in, itcat_id_in, month_in, year_in, date_block_in, shop_id_enc_in,\n",
    "                                 item_id_enc_in, itcat_id_enc_in, month_id_enc_in, year_id_enc_in, shop_item_lag_in,\n",
    "                                 shop_lag_in, item_lag_in, itcat_lag_in, item_name_in, itcat_name_in],\n",
    "                       outputs = model,\n",
    "                       name = 'nn_enc_dense_pfs4')\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "shop_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 12)        720         shop_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 20)        443400      item_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 12)        1008        itcat_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 4)         48          month_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 2)         6           year_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "date_block_in (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_item_lag_in (InputLayer)   (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_lag_in (InputLayer)       (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_name_in (InputLayer)       (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_name_in (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 12)           0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 20)           0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 12)           0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 4)            0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 2)            0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1)            2           date_block_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 4)            20          shop_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 4)            20          item_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 4)            20          itcat_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 4)            20          month_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 4)            20          year_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 11)           132         shop_item_lag_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 11)           132         shop_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 11)           132         item_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 11)           132         itcat_lag_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 5)            30          item_name_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 5)            30          itcat_name_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 125)          0           reshape_17[0][0]                 \n",
      "                                                                 reshape_18[0][0]                 \n",
      "                                                                 reshape_19[0][0]                 \n",
      "                                                                 reshape_20[0][0]                 \n",
      "                                                                 reshape_21[0][0]                 \n",
      "                                                                 dense_41[0][0]                   \n",
      "                                                                 dense_42[0][0]                   \n",
      "                                                                 dense_43[0][0]                   \n",
      "                                                                 dense_44[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "                                                                 dense_46[0][0]                   \n",
      "                                                                 dense_47[0][0]                   \n",
      "                                                                 dense_48[0][0]                   \n",
      "                                                                 dense_49[0][0]                   \n",
      "                                                                 dense_50[0][0]                   \n",
      "                                                                 dense_51[0][0]                   \n",
      "                                                                 dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1000)         126000      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000)         0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 500)          500500      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 500)          0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 150)          75150       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 150)          0           fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 15)           2265        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 1)            16          fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,149,803\n",
      "Trainable params: 1,149,803\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model_dense()\n",
    "model.compile('Adam', loss = 'mean_squared_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/600\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 2.6696 - val_loss: 2.6815\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.68152, saving model to nn_enc_model_dense_pfs4.hdf5\n",
      "Epoch 2/600\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 2.2474 - val_loss: 2.7125\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.68152\n",
      "Epoch 3/600\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 2.1206 - val_loss: 2.5328\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.68152 to 2.53284, saving model to nn_enc_model_dense_pfs4.hdf5\n",
      "Epoch 4/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 2.0361 - val_loss: 2.5065\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.53284 to 2.50652, saving model to nn_enc_model_dense_pfs4.hdf5\n",
      "Epoch 5/600\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 1.9646 - val_loss: 2.4503\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.50652 to 2.45029, saving model to nn_enc_model_dense_pfs4.hdf5\n",
      "Epoch 6/600\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 1.9025 - val_loss: 2.5642\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.45029\n",
      "Epoch 7/600\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.8440 - val_loss: 2.5467\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.45029\n",
      "Epoch 8/600\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.7901 - val_loss: 2.4988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.45029\n",
      "Epoch 9/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.7395 - val_loss: 2.5556\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.45029\n",
      "Epoch 10/600\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.6989 - val_loss: 2.6165\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.45029\n",
      "Epoch 11/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.6652 - val_loss: 2.6699\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.45029\n",
      "Epoch 12/600\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.6258 - val_loss: 2.8375\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.45029\n",
      "Epoch 13/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.5964 - val_loss: 2.6477\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.45029\n",
      "Epoch 14/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.5674 - val_loss: 2.5699\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.45029\n",
      "Epoch 15/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.5383 - val_loss: 2.6879\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.45029\n",
      "Epoch 16/600\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.5112 - val_loss: 2.7039\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.45029\n",
      "Epoch 17/600\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.4878 - val_loss: 2.6445\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.45029\n",
      "Epoch 18/600\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.4653 - val_loss: 2.6269\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.45029\n",
      "Epoch 19/600\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.4435 - val_loss: 2.6798\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.45029\n",
      "Epoch 20/600\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.4213 - val_loss: 2.7372\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.45029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd006c6748>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=15)\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_pfs4.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=2048, epochs=600, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [early_stopping, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dense():\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    shop_id_in = Input((1,), name = 'shop_id_in')\n",
    "    shop_id = Embedding(60,12)(shop_id_in)\n",
    "    shop_id = Reshape((12,))(shop_id)\n",
    "    layers.append(shop_id)\n",
    "    \n",
    "    item_id_in = Input((1,), name='item_id_in')\n",
    "    item_id = Embedding(22170,20)(item_id_in)\n",
    "    item_id = Reshape((20,))(item_id)\n",
    "    layers.append(item_id)\n",
    "    \n",
    "    itcat_id_in = Input((1,), name='itcat_in')\n",
    "    itcat_id = Embedding(84,12)(itcat_id_in)\n",
    "    itcat_id = Reshape((12,))(itcat_id)\n",
    "    layers.append(itcat_id)\n",
    "    \n",
    "    month_in = Input((1,), name='month_in')\n",
    "    month = Embedding(12,4)(month_in)\n",
    "    month = Reshape((4,))(month)\n",
    "    layers.append(month)\n",
    "    \n",
    "    year_in = Input((1,), name='year_in')\n",
    "    year = Embedding(3,2)(year_in)\n",
    "    year = Reshape((2,))(year)\n",
    "    layers.append(year)\n",
    "    \n",
    "    date_block_in = Input((1,), name='date_block_in')\n",
    "    date_block = Dense(1)(date_block_in)\n",
    "    layers.append(date_block)\n",
    "    \n",
    "    shop_id_enc_in = Input((4,), name='shop_id_end_in')\n",
    "    shop_id_enc = Dense(4)(shop_id_enc_in)\n",
    "    layers.append(shop_id_enc)\n",
    "    \n",
    "    item_id_enc_in = Input((4,), name='item_id_end_in')\n",
    "    item_id_enc = Dense(4)(item_id_enc_in)\n",
    "    layers.append(item_id_enc)\n",
    "    \n",
    "    itcat_id_enc_in = Input((4,), name='itcat_id_end_in')\n",
    "    itcat_id_enc = Dense(4)(itcat_id_enc_in)\n",
    "    layers.append(itcat_id_enc)\n",
    "    \n",
    "    month_id_enc_in = Input((4,), name='month_id_end_in')\n",
    "    month_id_enc = Dense(4)(month_id_enc_in)\n",
    "    layers.append(month_id_enc)\n",
    "    \n",
    "    year_id_enc_in = Input((4,), name='year_id_end_in')\n",
    "    year_id_enc = Dense(4)(year_id_enc_in)\n",
    "    layers.append(year_id_enc)\n",
    "    \n",
    "    shop_item_lag_in = Input((11,), name='shop_item_lag_in')\n",
    "    shop_item_lag = Dense(11)(shop_item_lag_in)\n",
    "    layers.append(shop_item_lag)\n",
    "    \n",
    "    shop_lag_in = Input((11,), name='shop_lag_in')\n",
    "    shop_lag = Dense(11)(shop_lag_in)\n",
    "    layers.append(shop_lag)\n",
    "    \n",
    "    item_lag_in = Input((11,), name='item_lag_in')\n",
    "    item_lag = Dense(11)(item_lag_in)\n",
    "    layers.append(item_lag)\n",
    "    \n",
    "    itcat_lag_in = Input((11,), name='itcat_lag_in')\n",
    "    itcat_lag = Dense(11)(itcat_lag_in)\n",
    "    layers.append(itcat_lag)\n",
    "    \n",
    "    item_name_in = Input((5,),name='item_name_in')\n",
    "    item_name = Dense(5)(item_name_in)\n",
    "    layers.append(item_name)\n",
    "    \n",
    "    itcat_name_in = Input((5,), name='itcat_name_in')\n",
    "    itcat_name = Dense(5)(itcat_name_in)\n",
    "    layers.append(itcat_name)\n",
    "    \n",
    "    model = Concatenate()(layers)\n",
    "    model = Dense(1000, activation='relu',name='fc1')(model)\n",
    "    #model = Dropout(0.3)(model)\n",
    "    \n",
    "    model = Dense(500, activation='relu', name='fc2')(model)\n",
    "    #model = Dropout(0.2)(model)\n",
    "    \n",
    "    model = Dense(150,activation='relu', name='fc3')(model)\n",
    "    #model = Dropout(0.1)(model)\n",
    "    \n",
    "    model = Dense(15, activation='relu',name='fc4')(model)\n",
    "    model= Dense(1,name='fc5')(model)\n",
    "    \n",
    "    final_model = Model(inputs = [shop_id_in, item_id_in, itcat_id_in, month_in, year_in, date_block_in, shop_id_enc_in,\n",
    "                                 item_id_enc_in, itcat_id_enc_in, month_id_enc_in, year_id_enc_in, shop_item_lag_in,\n",
    "                                 shop_lag_in, item_lag_in, itcat_lag_in, item_name_in, itcat_name_in],\n",
    "                       outputs = model,\n",
    "                       name = 'nn_enc_dense_pfs4')\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "shop_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 1, 12)        720         shop_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 1, 20)        443400      item_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 1, 12)        1008        itcat_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 1, 4)         48          month_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 1, 2)         6           year_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "date_block_in (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_item_lag_in (InputLayer)   (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_lag_in (InputLayer)       (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_name_in (InputLayer)       (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_name_in (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_32 (Reshape)            (None, 12)           0           embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 20)           0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)            (None, 12)           0           embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_35 (Reshape)            (None, 4)            0           embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)            (None, 2)            0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 1)            2           date_block_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 4)            20          shop_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 4)            20          item_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 4)            20          itcat_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 4)            20          month_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 4)            20          year_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 11)           132         shop_item_lag_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 11)           132         shop_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 11)           132         item_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 11)           132         itcat_lag_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 5)            30          item_name_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 5)            30          itcat_name_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 125)          0           reshape_32[0][0]                 \n",
      "                                                                 reshape_33[0][0]                 \n",
      "                                                                 reshape_34[0][0]                 \n",
      "                                                                 reshape_35[0][0]                 \n",
      "                                                                 reshape_36[0][0]                 \n",
      "                                                                 dense_77[0][0]                   \n",
      "                                                                 dense_78[0][0]                   \n",
      "                                                                 dense_79[0][0]                   \n",
      "                                                                 dense_80[0][0]                   \n",
      "                                                                 dense_81[0][0]                   \n",
      "                                                                 dense_82[0][0]                   \n",
      "                                                                 dense_83[0][0]                   \n",
      "                                                                 dense_84[0][0]                   \n",
      "                                                                 dense_85[0][0]                   \n",
      "                                                                 dense_86[0][0]                   \n",
      "                                                                 dense_87[0][0]                   \n",
      "                                                                 dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1000)         126000      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 500)          500500      fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 150)          75150       fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 15)           2265        fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 1)            16          fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,149,803\n",
      "Trainable params: 1,149,803\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model_dense()\n",
    "model.compile('Adam', loss = 'mean_squared_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 1.4376 - val_loss: 2.5177\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.51767, saving model to nn_enc_model_dense_wo_dropout_pfs4.hdf5\n",
      "Epoch 2/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 1.3910 - val_loss: 2.4329\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.51767 to 2.43287, saving model to nn_enc_model_dense_wo_dropout_pfs4.hdf5\n",
      "Epoch 3/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 1.3479 - val_loss: 2.4762\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.43287\n",
      "Epoch 4/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 1.3097 - val_loss: 2.6182\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.43287\n",
      "Epoch 5/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 1.2693 - val_loss: 2.6004\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.43287\n",
      "Epoch 6/100\n",
      "1483908/1483908 [==============================] - 90s 61us/step - loss: 1.2319 - val_loss: 2.6657\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.43287\n",
      "Epoch 7/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 1.1897 - val_loss: 2.8091\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.43287\n",
      "Epoch 8/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 1.1536 - val_loss: 2.6785\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.43287\n",
      "Epoch 9/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 1.1078 - val_loss: 2.8290\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.43287\n",
      "Epoch 10/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 1.0691 - val_loss: 2.6559\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.43287\n",
      "Epoch 11/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 1.0316 - val_loss: 2.6581\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.43287\n",
      "Epoch 12/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.9931 - val_loss: 2.7467\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.43287\n",
      "Epoch 13/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.9554 - val_loss: 2.8239\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.43287\n",
      "Epoch 14/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.9214 - val_loss: 2.7637\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.43287\n",
      "Epoch 15/100\n",
      "1483908/1483908 [==============================] - 91s 61us/step - loss: 0.8863 - val_loss: 2.8428\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.43287\n",
      "Epoch 16/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.8523 - val_loss: 2.9636\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.43287\n",
      "Epoch 17/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.8236 - val_loss: 2.8269\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.43287\n",
      "Epoch 18/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.7960 - val_loss: 2.9082\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.43287\n",
      "Epoch 19/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.7722 - val_loss: 2.9807\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.43287\n",
      "Epoch 20/100\n",
      "1483908/1483908 [==============================] - 92s 62us/step - loss: 0.7451 - val_loss: 2.9213\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.43287\n",
      "Epoch 21/100\n",
      "1483908/1483908 [==============================] - 90s 61us/step - loss: 0.7186 - val_loss: 2.9339\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.43287\n",
      "Epoch 22/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.6976 - val_loss: 2.9432\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.43287\n",
      "Epoch 23/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.6762 - val_loss: 2.9985\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.43287\n",
      "Epoch 24/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.6552 - val_loss: 3.0815\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.43287\n",
      "Epoch 25/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.6359 - val_loss: 3.0195\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.43287\n",
      "Epoch 26/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.6201 - val_loss: 3.1009\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.43287\n",
      "Epoch 27/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.6023 - val_loss: 3.0516\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.43287\n",
      "Epoch 28/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.5877 - val_loss: 2.9919\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.43287\n",
      "Epoch 29/100\n",
      "1483908/1483908 [==============================] - 91s 61us/step - loss: 0.5713 - val_loss: 3.1184\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.43287\n",
      "Epoch 30/100\n",
      "1483908/1483908 [==============================] - 90s 61us/step - loss: 0.5571 - val_loss: 3.1716\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.43287\n",
      "Epoch 31/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.5459 - val_loss: 3.1997\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.43287\n",
      "Epoch 32/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.5356 - val_loss: 3.0911\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.43287\n",
      "Epoch 33/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.5226 - val_loss: 3.1071\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.43287\n",
      "Epoch 34/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.5107 - val_loss: 3.1117\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.43287\n",
      "Epoch 35/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4992 - val_loss: 3.1097\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.43287\n",
      "Epoch 36/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4887 - val_loss: 3.1929\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.43287\n",
      "Epoch 37/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4769 - val_loss: 3.2362\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.43287\n",
      "Epoch 38/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4693 - val_loss: 3.1850\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.43287\n",
      "Epoch 39/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4599 - val_loss: 3.1223\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.43287\n",
      "Epoch 40/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4541 - val_loss: 3.1401\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.43287\n",
      "Epoch 41/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4435 - val_loss: 3.1235\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.43287\n",
      "Epoch 42/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.4369 - val_loss: 3.2715\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.43287\n",
      "Epoch 43/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4300 - val_loss: 3.2416\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.43287\n",
      "Epoch 44/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.4219 - val_loss: 3.2554\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.43287\n",
      "Epoch 45/100\n",
      "1483908/1483908 [==============================] - 90s 61us/step - loss: 0.4177 - val_loss: 3.1877\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.43287\n",
      "Epoch 46/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.4089 - val_loss: 3.2707\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.43287\n",
      "Epoch 47/100\n",
      "1483908/1483908 [==============================] - 90s 61us/step - loss: 0.4006 - val_loss: 3.2524\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.43287\n",
      "Epoch 48/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.3954 - val_loss: 3.3318\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.43287\n",
      "Epoch 49/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.3901 - val_loss: 3.3364\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.43287\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.3855 - val_loss: 3.2276\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.43287\n",
      "Epoch 51/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3796 - val_loss: 3.2870\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.43287\n",
      "Epoch 52/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3741 - val_loss: 3.3294\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.43287\n",
      "Epoch 53/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3705 - val_loss: 3.3354\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.43287\n",
      "Epoch 54/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3653 - val_loss: 3.2828\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.43287\n",
      "Epoch 55/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3618 - val_loss: 3.2333\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.43287\n",
      "Epoch 56/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3544 - val_loss: 3.2720\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.43287\n",
      "Epoch 57/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3494 - val_loss: 3.1303\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.43287\n",
      "Epoch 58/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3510 - val_loss: 3.2972\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.43287\n",
      "Epoch 59/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.3388 - val_loss: 3.3524\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.43287\n",
      "Epoch 60/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.3374 - val_loss: 3.2910\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.43287\n",
      "Epoch 61/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.3351 - val_loss: 3.2070\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.43287\n",
      "Epoch 62/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3308 - val_loss: 3.2366\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.43287\n",
      "Epoch 63/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.3273 - val_loss: 3.3372\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.43287\n",
      "Epoch 64/100\n",
      "1483908/1483908 [==============================] - 88s 59us/step - loss: 0.3233 - val_loss: 3.2618\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.43287\n",
      "Epoch 65/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.3195 - val_loss: 3.3594\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.43287\n",
      "Epoch 66/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.3174 - val_loss: 3.3120\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.43287\n",
      "Epoch 67/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.3126 - val_loss: 3.3030\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.43287\n",
      "Epoch 68/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.3090 - val_loss: 3.3344\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.43287\n",
      "Epoch 69/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.3110 - val_loss: 3.2908\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.43287\n",
      "Epoch 70/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.3052 - val_loss: 3.2973\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.43287\n",
      "Epoch 71/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.3008 - val_loss: 3.3449\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.43287\n",
      "Epoch 72/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2989 - val_loss: 3.2561\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.43287\n",
      "Epoch 73/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2954 - val_loss: 3.2986\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.43287\n",
      "Epoch 74/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2924 - val_loss: 3.3033\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.43287\n",
      "Epoch 75/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2889 - val_loss: 3.2082\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.43287\n",
      "Epoch 76/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2895 - val_loss: 3.2515\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.43287\n",
      "Epoch 77/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2853 - val_loss: 3.1957\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.43287\n",
      "Epoch 78/100\n",
      "1483908/1483908 [==============================] - 88s 60us/step - loss: 0.2837 - val_loss: 3.2937\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.43287\n",
      "Epoch 79/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2827 - val_loss: 3.3082\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.43287\n",
      "Epoch 80/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2780 - val_loss: 3.3410\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.43287\n",
      "Epoch 81/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2753 - val_loss: 3.3246\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.43287\n",
      "Epoch 82/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2745 - val_loss: 3.3195\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.43287\n",
      "Epoch 83/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2710 - val_loss: 3.2863\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.43287\n",
      "Epoch 84/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2685 - val_loss: 3.3302\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.43287\n",
      "Epoch 85/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2686 - val_loss: 3.4648\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.43287\n",
      "Epoch 86/100\n",
      "1483908/1483908 [==============================] - 93s 63us/step - loss: 0.2635 - val_loss: 3.2340\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.43287\n",
      "Epoch 87/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2621 - val_loss: 3.4254\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.43287\n",
      "Epoch 88/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2619 - val_loss: 3.4196\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.43287\n",
      "Epoch 89/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2599 - val_loss: 3.3474\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.43287\n",
      "Epoch 90/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2553 - val_loss: 3.3963\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.43287\n",
      "Epoch 91/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2550 - val_loss: 3.3281\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.43287\n",
      "Epoch 92/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.2553 - val_loss: 3.3827\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.43287\n",
      "Epoch 93/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2514 - val_loss: 3.3651\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.43287\n",
      "Epoch 94/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2511 - val_loss: 3.3861\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.43287\n",
      "Epoch 95/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2502 - val_loss: 3.3037\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.43287\n",
      "Epoch 96/100\n",
      "1483908/1483908 [==============================] - 90s 60us/step - loss: 0.2466 - val_loss: 3.3540\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.43287\n",
      "Epoch 97/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2493 - val_loss: 3.3689\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.43287\n",
      "Epoch 98/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2428 - val_loss: 3.3828\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.43287\n",
      "Epoch 99/100\n",
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2424 - val_loss: 3.3864\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.43287\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 89s 60us/step - loss: 0.2433 - val_loss: 3.3838\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.43287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd713964a8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss')\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_wo_dropout_pfs4.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=2048, epochs=100, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/100\n",
      "1483908/1483908 [==============================] - 85s 57us/step - loss: 0.2057 - val_loss: 3.3227\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.32274, saving model to nn_enc_model_dense_wo_dropout_2_pfs4.hdf5\n",
      "Epoch 2/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1810 - val_loss: 3.3094\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.32274 to 3.30943, saving model to nn_enc_model_dense_wo_dropout_2_pfs4.hdf5\n",
      "Epoch 3/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1764 - val_loss: 3.3747\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.30943\n",
      "Epoch 4/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1768 - val_loss: 3.4191\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.30943\n",
      "Epoch 5/100\n",
      "1483908/1483908 [==============================] - 84s 57us/step - loss: 0.1808 - val_loss: 3.3632\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.30943\n",
      "Epoch 6/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1846 - val_loss: 3.4047\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.30943\n",
      "Epoch 7/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1894 - val_loss: 3.3947\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.30943\n",
      "Epoch 8/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1930 - val_loss: 3.3847\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.30943\n",
      "Epoch 9/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1930 - val_loss: 3.4333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.30943\n",
      "Epoch 10/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1904 - val_loss: 3.4588\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.30943\n",
      "Epoch 11/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1889 - val_loss: 3.4356\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.30943\n",
      "Epoch 12/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1885 - val_loss: 3.4321\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.30943\n",
      "Epoch 13/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1878 - val_loss: 3.4270\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.30943\n",
      "Epoch 14/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1866 - val_loss: 3.4141\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.30943\n",
      "Epoch 15/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1857 - val_loss: 3.4201\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.30943\n",
      "Epoch 16/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1847 - val_loss: 3.4423\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.30943\n",
      "Epoch 17/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1842 - val_loss: 3.4736\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.30943\n",
      "Epoch 18/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1829 - val_loss: 3.4158\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.30943\n",
      "Epoch 19/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1815 - val_loss: 3.4374\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.30943\n",
      "Epoch 20/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1806 - val_loss: 3.3595\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.30943\n",
      "Epoch 21/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1815 - val_loss: 3.3775\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.30943\n",
      "Epoch 22/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1827 - val_loss: 3.4530\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.30943\n",
      "Epoch 23/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1793 - val_loss: 3.4352\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.30943\n",
      "Epoch 24/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1774 - val_loss: 3.3724\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.30943\n",
      "Epoch 25/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1764 - val_loss: 3.4726\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.30943\n",
      "Epoch 26/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1759 - val_loss: 3.3964\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.30943\n",
      "Epoch 27/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1768 - val_loss: 3.4401\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.30943\n",
      "Epoch 28/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1746 - val_loss: 3.4137\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.30943\n",
      "Epoch 29/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1729 - val_loss: 3.4704\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.30943\n",
      "Epoch 30/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1730 - val_loss: 3.4614\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.30943\n",
      "Epoch 31/100\n",
      "1483908/1483908 [==============================] - 84s 56us/step - loss: 0.1769 - val_loss: 3.4389\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.30943\n",
      "Epoch 32/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1738 - val_loss: 3.4184\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.30943\n",
      "Epoch 33/100\n",
      "1483908/1483908 [==============================] - 84s 56us/step - loss: 0.1712 - val_loss: 3.4000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.30943\n",
      "Epoch 34/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1699 - val_loss: 3.4723\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.30943\n",
      "Epoch 35/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1706 - val_loss: 3.4723\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.30943\n",
      "Epoch 36/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1700 - val_loss: 3.3873\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.30943\n",
      "Epoch 37/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1688 - val_loss: 3.4553\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.30943\n",
      "Epoch 38/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1686 - val_loss: 3.4527\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.30943\n",
      "Epoch 39/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1680 - val_loss: 3.4288\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.30943\n",
      "Epoch 40/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1686 - val_loss: 3.4788\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.30943\n",
      "Epoch 41/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1680 - val_loss: 3.4669\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.30943\n",
      "Epoch 42/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1669 - val_loss: 3.5397\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.30943\n",
      "Epoch 43/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1661 - val_loss: 3.5145\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.30943\n",
      "Epoch 44/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1665 - val_loss: 3.4889\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.30943\n",
      "Epoch 45/100\n",
      "1483908/1483908 [==============================] - 86s 58us/step - loss: 0.1647 - val_loss: 3.5388\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.30943\n",
      "Epoch 46/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1634 - val_loss: 3.4715\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.30943\n",
      "Epoch 47/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1634 - val_loss: 3.5019\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.30943\n",
      "Epoch 48/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1624 - val_loss: 3.5265\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.30943\n",
      "Epoch 49/100\n",
      "1483908/1483908 [==============================] - 84s 56us/step - loss: 0.1629 - val_loss: 3.4662\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.30943\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1623 - val_loss: 3.5107\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.30943\n",
      "Epoch 51/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1632 - val_loss: 3.4982\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.30943\n",
      "Epoch 52/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1605 - val_loss: 3.5251\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.30943\n",
      "Epoch 53/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1607 - val_loss: 3.5080\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.30943\n",
      "Epoch 54/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1603 - val_loss: 3.5244\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.30943\n",
      "Epoch 55/100\n",
      "1483908/1483908 [==============================] - 82s 56us/step - loss: 0.1598 - val_loss: 3.4592\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.30943\n",
      "Epoch 56/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1589 - val_loss: 3.4878\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.30943\n",
      "Epoch 57/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1591 - val_loss: 3.5397\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.30943\n",
      "Epoch 58/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1590 - val_loss: 3.5326\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.30943\n",
      "Epoch 59/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1575 - val_loss: 3.5419\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.30943\n",
      "Epoch 60/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1569 - val_loss: 3.5244\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.30943\n",
      "Epoch 61/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1572 - val_loss: 3.5371\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.30943\n",
      "Epoch 62/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1569 - val_loss: 3.5324\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.30943\n",
      "Epoch 63/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1555 - val_loss: 3.4763\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.30943\n",
      "Epoch 64/100\n",
      "1483908/1483908 [==============================] - 82s 56us/step - loss: 0.1570 - val_loss: 3.4739\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.30943\n",
      "Epoch 65/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1554 - val_loss: 3.5714\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.30943\n",
      "Epoch 66/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1542 - val_loss: 3.5131\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.30943\n",
      "Epoch 67/100\n",
      "1483908/1483908 [==============================] - 82s 56us/step - loss: 0.1545 - val_loss: 3.5243\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.30943\n",
      "Epoch 68/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1539 - val_loss: 3.5653\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.30943\n",
      "Epoch 69/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1543 - val_loss: 3.6259\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.30943\n",
      "Epoch 70/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1541 - val_loss: 3.5179\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.30943\n",
      "Epoch 71/100\n",
      "1483908/1483908 [==============================] - 82s 56us/step - loss: 0.1526 - val_loss: 3.5242\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.30943\n",
      "Epoch 72/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1525 - val_loss: 3.5735\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.30943\n",
      "Epoch 73/100\n",
      "1483908/1483908 [==============================] - 82s 55us/step - loss: 0.1531 - val_loss: 3.5427\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.30943\n",
      "Epoch 74/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1511 - val_loss: 3.4952\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.30943\n",
      "Epoch 75/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1514 - val_loss: 3.5030\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.30943\n",
      "Epoch 76/100\n",
      "1483908/1483908 [==============================] - 84s 56us/step - loss: 0.1510 - val_loss: 3.5196\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.30943\n",
      "Epoch 77/100\n",
      "1483908/1483908 [==============================] - 84s 57us/step - loss: 0.1523 - val_loss: 3.5204\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.30943\n",
      "Epoch 78/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1546 - val_loss: 3.5426\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.30943\n",
      "Epoch 79/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1523 - val_loss: 3.4629\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.30943\n",
      "Epoch 80/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1490 - val_loss: 3.5453\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.30943\n",
      "Epoch 81/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1478 - val_loss: 3.4983\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.30943\n",
      "Epoch 82/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1477 - val_loss: 3.5321\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.30943\n",
      "Epoch 83/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1473 - val_loss: 3.5165\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.30943\n",
      "Epoch 84/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1481 - val_loss: 3.5736\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.30943\n",
      "Epoch 85/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1492 - val_loss: 3.5454\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.30943\n",
      "Epoch 86/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1483 - val_loss: 3.5195\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.30943\n",
      "Epoch 87/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1471 - val_loss: 3.4992\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.30943\n",
      "Epoch 88/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1462 - val_loss: 3.5495\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.30943\n",
      "Epoch 89/100\n",
      "1483908/1483908 [==============================] - 86s 58us/step - loss: 0.1464 - val_loss: 3.5471\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.30943\n",
      "Epoch 90/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1460 - val_loss: 3.5589\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.30943\n",
      "Epoch 91/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1450 - val_loss: 3.5390\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.30943\n",
      "Epoch 92/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1454 - val_loss: 3.5685\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.30943\n",
      "Epoch 93/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1460 - val_loss: 3.5421\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.30943\n",
      "Epoch 94/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1451 - val_loss: 3.5355\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.30943\n",
      "Epoch 95/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1444 - val_loss: 3.5586\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.30943\n",
      "Epoch 96/100\n",
      "1483908/1483908 [==============================] - 84s 56us/step - loss: 0.1443 - val_loss: 3.5198\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.30943\n",
      "Epoch 97/100\n",
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1456 - val_loss: 3.5521\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.30943\n",
      "Epoch 98/100\n",
      "1483908/1483908 [==============================] - 84s 56us/step - loss: 0.1449 - val_loss: 3.4926\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.30943\n",
      "Epoch 99/100\n",
      "1483908/1483908 [==============================] - 84s 57us/step - loss: 0.1442 - val_loss: 3.5885\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.30943\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 83s 56us/step - loss: 0.1425 - val_loss: 3.5524\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.30943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd713a1da0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss', patience=15)\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_wo_dropout_2_pfs4.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=4096, epochs=100, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dropout, without early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dense():\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    shop_id_in = Input((1,), name = 'shop_id_in')\n",
    "    shop_id = Embedding(60,12)(shop_id_in)\n",
    "    shop_id = Reshape((12,))(shop_id)\n",
    "    layers.append(shop_id)\n",
    "    \n",
    "    item_id_in = Input((1,), name='item_id_in')\n",
    "    item_id = Embedding(22170,20)(item_id_in)\n",
    "    item_id = Reshape((20,))(item_id)\n",
    "    layers.append(item_id)\n",
    "    \n",
    "    itcat_id_in = Input((1,), name='itcat_in')\n",
    "    itcat_id = Embedding(84,12)(itcat_id_in)\n",
    "    itcat_id = Reshape((12,))(itcat_id)\n",
    "    layers.append(itcat_id)\n",
    "    \n",
    "    month_in = Input((1,), name='month_in')\n",
    "    month = Embedding(12,4)(month_in)\n",
    "    month = Reshape((4,))(month)\n",
    "    layers.append(month)\n",
    "    \n",
    "    year_in = Input((1,), name='year_in')\n",
    "    year = Embedding(3,2)(year_in)\n",
    "    year = Reshape((2,))(year)\n",
    "    layers.append(year)\n",
    "    \n",
    "    date_block_in = Input((1,), name='date_block_in')\n",
    "    date_block = Dense(1)(date_block_in)\n",
    "    layers.append(date_block)\n",
    "    \n",
    "    shop_id_enc_in = Input((4,), name='shop_id_end_in')\n",
    "    shop_id_enc = Dense(4)(shop_id_enc_in)\n",
    "    layers.append(shop_id_enc)\n",
    "    \n",
    "    item_id_enc_in = Input((4,), name='item_id_end_in')\n",
    "    item_id_enc = Dense(4)(item_id_enc_in)\n",
    "    layers.append(item_id_enc)\n",
    "    \n",
    "    itcat_id_enc_in = Input((4,), name='itcat_id_end_in')\n",
    "    itcat_id_enc = Dense(4)(itcat_id_enc_in)\n",
    "    layers.append(itcat_id_enc)\n",
    "    \n",
    "    month_id_enc_in = Input((4,), name='month_id_end_in')\n",
    "    month_id_enc = Dense(4)(month_id_enc_in)\n",
    "    layers.append(month_id_enc)\n",
    "    \n",
    "    year_id_enc_in = Input((4,), name='year_id_end_in')\n",
    "    year_id_enc = Dense(4)(year_id_enc_in)\n",
    "    layers.append(year_id_enc)\n",
    "    \n",
    "    shop_item_lag_in = Input((11,), name='shop_item_lag_in')\n",
    "    shop_item_lag = Dense(11)(shop_item_lag_in)\n",
    "    layers.append(shop_item_lag)\n",
    "    \n",
    "    shop_lag_in = Input((11,), name='shop_lag_in')\n",
    "    shop_lag = Dense(11)(shop_lag_in)\n",
    "    layers.append(shop_lag)\n",
    "    \n",
    "    item_lag_in = Input((11,), name='item_lag_in')\n",
    "    item_lag = Dense(11)(item_lag_in)\n",
    "    layers.append(item_lag)\n",
    "    \n",
    "    itcat_lag_in = Input((11,), name='itcat_lag_in')\n",
    "    itcat_lag = Dense(11)(itcat_lag_in)\n",
    "    layers.append(itcat_lag)\n",
    "    \n",
    "    item_name_in = Input((5,),name='item_name_in')\n",
    "    item_name = Dense(5)(item_name_in)\n",
    "    layers.append(item_name)\n",
    "    \n",
    "    itcat_name_in = Input((5,), name='itcat_name_in')\n",
    "    itcat_name = Dense(5)(itcat_name_in)\n",
    "    layers.append(itcat_name)\n",
    "    \n",
    "    model = Concatenate()(layers)\n",
    "    model = Dense(1000, activation='relu',name='fc1')(model)\n",
    "    model = Dropout(0.3)(model)\n",
    "    \n",
    "    model = Dense(500, activation='relu', name='fc2')(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "    \n",
    "    model = Dense(150,activation='relu', name='fc3')(model)\n",
    "    model = Dropout(0.1)(model)\n",
    "    \n",
    "    model = Dense(15, activation='relu',name='fc4')(model)\n",
    "    model= Dense(1,name='fc5')(model)\n",
    "    \n",
    "    final_model = Model(inputs = [shop_id_in, item_id_in, itcat_id_in, month_in, year_in, date_block_in, shop_id_enc_in,\n",
    "                                 item_id_enc_in, itcat_id_enc_in, month_id_enc_in, year_id_enc_in, shop_item_lag_in,\n",
    "                                 shop_lag_in, item_lag_in, itcat_lag_in, item_name_in, itcat_name_in],\n",
    "                       outputs = model,\n",
    "                       name = 'nn_enc_dense_pfs4')\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "shop_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 1, 12)        720         shop_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 1, 20)        443400      item_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 1, 12)        1008        itcat_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 1, 4)         48          month_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 1, 2)         6           year_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "date_block_in (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_item_lag_in (InputLayer)   (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_lag_in (InputLayer)       (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_name_in (InputLayer)       (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_name_in (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_37 (Reshape)            (None, 12)           0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_38 (Reshape)            (None, 20)           0           embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_39 (Reshape)            (None, 12)           0           embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_40 (Reshape)            (None, 4)            0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_41 (Reshape)            (None, 2)            0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 1)            2           date_block_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 4)            20          shop_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 4)            20          item_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 4)            20          itcat_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 4)            20          month_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 4)            20          year_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 11)           132         shop_item_lag_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 11)           132         shop_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 11)           132         item_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 11)           132         itcat_lag_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 5)            30          item_name_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 5)            30          itcat_name_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 125)          0           reshape_37[0][0]                 \n",
      "                                                                 reshape_38[0][0]                 \n",
      "                                                                 reshape_39[0][0]                 \n",
      "                                                                 reshape_40[0][0]                 \n",
      "                                                                 reshape_41[0][0]                 \n",
      "                                                                 dense_89[0][0]                   \n",
      "                                                                 dense_90[0][0]                   \n",
      "                                                                 dense_91[0][0]                   \n",
      "                                                                 dense_92[0][0]                   \n",
      "                                                                 dense_93[0][0]                   \n",
      "                                                                 dense_94[0][0]                   \n",
      "                                                                 dense_95[0][0]                   \n",
      "                                                                 dense_96[0][0]                   \n",
      "                                                                 dense_97[0][0]                   \n",
      "                                                                 dense_98[0][0]                   \n",
      "                                                                 dense_99[0][0]                   \n",
      "                                                                 dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1000)         126000      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1000)         0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 500)          500500      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 500)          0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 150)          75150       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 150)          0           fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 15)           2265        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 1)            16          fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,149,803\n",
      "Trainable params: 1,149,803\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model_dense()\n",
    "model.compile('Adam', loss = 'mean_squared_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 2.8015 - val_loss: 2.8944\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.89442, saving model to nn_enc_model_dense_with_dropout_pfs4.hdf5\n",
      "Epoch 2/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 2.2984 - val_loss: 2.6581\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.89442 to 2.65813, saving model to nn_enc_model_dense_with_dropout_pfs4.hdf5\n",
      "Epoch 3/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 2.1562 - val_loss: 2.5962\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.65813 to 2.59625, saving model to nn_enc_model_dense_with_dropout_pfs4.hdf5\n",
      "Epoch 4/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 2.0670 - val_loss: 2.6130\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.59625\n",
      "Epoch 5/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 2.0092 - val_loss: 2.5202\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.59625 to 2.52021, saving model to nn_enc_model_dense_with_dropout_pfs4.hdf5\n",
      "Epoch 6/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.9430 - val_loss: 2.5813\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.52021\n",
      "Epoch 7/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.8990 - val_loss: 2.5746\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.52021\n",
      "Epoch 8/100\n",
      "1483908/1483908 [==============================] - 122s 83us/step - loss: 1.8503 - val_loss: 2.6862\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.52021\n",
      "Epoch 9/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.7963 - val_loss: 2.6224\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.52021\n",
      "Epoch 10/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.7554 - val_loss: 2.6126\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.52021\n",
      "Epoch 11/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.7128 - val_loss: 2.6622\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.52021\n",
      "Epoch 12/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.6771 - val_loss: 2.6476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.52021\n",
      "Epoch 13/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.6470 - val_loss: 2.6250\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.52021\n",
      "Epoch 14/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.6171 - val_loss: 2.5932\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.52021\n",
      "Epoch 15/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.5888 - val_loss: 2.6307\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.52021\n",
      "Epoch 16/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.5649 - val_loss: 2.6916\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.52021\n",
      "Epoch 17/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.5382 - val_loss: 2.6937\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.52021\n",
      "Epoch 18/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.5173 - val_loss: 2.6806\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.52021\n",
      "Epoch 19/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.4910 - val_loss: 2.7269\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.52021\n",
      "Epoch 20/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.4714 - val_loss: 2.7382\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.52021\n",
      "Epoch 21/100\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 1.4519 - val_loss: 2.7468\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.52021\n",
      "Epoch 22/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.4298 - val_loss: 2.7705\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.52021\n",
      "Epoch 23/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.4113 - val_loss: 2.8888\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.52021\n",
      "Epoch 24/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.3916 - val_loss: 2.8758\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.52021\n",
      "Epoch 25/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.3780 - val_loss: 2.8371\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.52021\n",
      "Epoch 26/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.3605 - val_loss: 2.8214\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.52021\n",
      "Epoch 27/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.3438 - val_loss: 2.7225\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.52021\n",
      "Epoch 28/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.3274 - val_loss: 2.8689\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.52021\n",
      "Epoch 29/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.3092 - val_loss: 2.9001\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.52021\n",
      "Epoch 30/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.2921 - val_loss: 2.8563\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.52021\n",
      "Epoch 31/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.2841 - val_loss: 2.7930\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.52021\n",
      "Epoch 32/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.2635 - val_loss: 2.8114\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.52021\n",
      "Epoch 33/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.2531 - val_loss: 2.9179\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.52021\n",
      "Epoch 34/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.2378 - val_loss: 2.7657\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.52021\n",
      "Epoch 35/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.2294 - val_loss: 2.8213\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.52021\n",
      "Epoch 36/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.2123 - val_loss: 2.9661\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.52021\n",
      "Epoch 37/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.2040 - val_loss: 2.8999\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.52021\n",
      "Epoch 38/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.1857 - val_loss: 2.8912\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.52021\n",
      "Epoch 39/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.1745 - val_loss: 2.8625\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.52021\n",
      "Epoch 40/100\n",
      "1483908/1483908 [==============================] - 130s 87us/step - loss: 1.1711 - val_loss: 2.8688\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.52021\n",
      "Epoch 41/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.1538 - val_loss: 2.9145\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.52021\n",
      "Epoch 42/100\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 1.1441 - val_loss: 3.0038\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.52021\n",
      "Epoch 43/100\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 1.1355 - val_loss: 2.8614\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.52021\n",
      "Epoch 44/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.1259 - val_loss: 2.8586\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.52021\n",
      "Epoch 45/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.1135 - val_loss: 2.8621\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.52021\n",
      "Epoch 46/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 1.1055 - val_loss: 2.8885\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.52021\n",
      "Epoch 47/100\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 1.0969 - val_loss: 2.9077\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.52021\n",
      "Epoch 48/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.0852 - val_loss: 2.9440\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.52021\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.0801 - val_loss: 2.9560\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.52021\n",
      "Epoch 50/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 1.0729 - val_loss: 2.9217\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.52021\n",
      "Epoch 51/100\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 1.0673 - val_loss: 2.8914\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.52021\n",
      "Epoch 52/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0546 - val_loss: 2.8705\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.52021\n",
      "Epoch 53/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0513 - val_loss: 2.9435\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.52021\n",
      "Epoch 54/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0448 - val_loss: 2.8716\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.52021\n",
      "Epoch 55/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0376 - val_loss: 2.8751\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.52021\n",
      "Epoch 56/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 1.0279 - val_loss: 3.0264\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.52021\n",
      "Epoch 57/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0245 - val_loss: 2.9089\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.52021\n",
      "Epoch 58/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0203 - val_loss: 2.8911\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.52021\n",
      "Epoch 59/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 1.0134 - val_loss: 2.9533\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.52021\n",
      "Epoch 60/100\n",
      "1483908/1483908 [==============================] - 122s 83us/step - loss: 1.0060 - val_loss: 2.9632\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.52021\n",
      "Epoch 61/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9999 - val_loss: 2.8397\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.52021\n",
      "Epoch 62/100\n",
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 0.9989 - val_loss: 2.9736\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.52021\n",
      "Epoch 63/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9916 - val_loss: 2.8800\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.52021\n",
      "Epoch 64/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9868 - val_loss: 2.9416\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.52021\n",
      "Epoch 65/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9823 - val_loss: 2.8756\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.52021\n",
      "Epoch 66/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9784 - val_loss: 2.9724\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.52021\n",
      "Epoch 67/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9726 - val_loss: 3.0043\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.52021\n",
      "Epoch 68/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 0.9686 - val_loss: 2.9654\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.52021\n",
      "Epoch 69/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9607 - val_loss: 2.8840\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.52021\n",
      "Epoch 70/100\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 0.9626 - val_loss: 2.9179\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.52021\n",
      "Epoch 71/100\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 0.9573 - val_loss: 2.9825\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.52021\n",
      "Epoch 72/100\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 0.9511 - val_loss: 2.9956\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.52021\n",
      "Epoch 73/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9499 - val_loss: 2.9049\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.52021\n",
      "Epoch 74/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9425 - val_loss: 2.9703\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.52021\n",
      "Epoch 75/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 0.9401 - val_loss: 2.9112\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.52021\n",
      "Epoch 76/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 0.9357 - val_loss: 3.0165\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.52021\n",
      "Epoch 77/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9287 - val_loss: 2.9431\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.52021\n",
      "Epoch 78/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9324 - val_loss: 2.9904\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.52021\n",
      "Epoch 79/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9267 - val_loss: 2.8597\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.52021\n",
      "Epoch 80/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9219 - val_loss: 2.9298\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.52021\n",
      "Epoch 81/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9203 - val_loss: 2.9502\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.52021\n",
      "Epoch 82/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9179 - val_loss: 2.9388\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.52021\n",
      "Epoch 83/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9132 - val_loss: 2.9101\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.52021\n",
      "Epoch 84/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9092 - val_loss: 2.9473\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.52021\n",
      "Epoch 85/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 0.9084 - val_loss: 2.8779\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.52021\n",
      "Epoch 86/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9051 - val_loss: 2.9734\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.52021\n",
      "Epoch 87/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.9038 - val_loss: 2.8938\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.52021\n",
      "Epoch 88/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.8967 - val_loss: 2.9911\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.52021\n",
      "Epoch 89/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.8964 - val_loss: 3.0212\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.52021\n",
      "Epoch 90/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.8928 - val_loss: 2.9445\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.52021\n",
      "Epoch 91/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.8928 - val_loss: 2.9842\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.52021\n",
      "Epoch 92/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 0.8913 - val_loss: 2.8717\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.52021\n",
      "Epoch 93/100\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 0.8845 - val_loss: 2.9389\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.52021\n",
      "Epoch 94/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 0.8831 - val_loss: 2.9445\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.52021\n",
      "Epoch 95/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.8841 - val_loss: 2.9632\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.52021\n",
      "Epoch 96/100\n",
      "1483908/1483908 [==============================] - 123s 83us/step - loss: 0.8806 - val_loss: 2.9477\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.52021\n",
      "Epoch 97/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 0.8765 - val_loss: 2.8995\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.52021\n",
      "Epoch 98/100\n",
      "1483908/1483908 [==============================] - 128s 87us/step - loss: 0.8789 - val_loss: 2.8998\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.52021\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 122s 82us/step - loss: 0.8744 - val_loss: 2.9022\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.52021\n",
      "Epoch 100/100\n",
      "1483908/1483908 [==============================] - 124s 83us/step - loss: 0.8707 - val_loss: 2.9509\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.52021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd71327748>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss')\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_with_dropout_pfs4.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=2048, epochs=100, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Learning Curve')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['val_loss'], '-', label = 'val_loss' )\n",
    "plt.plot(model.history.history['loss'], '-', label = 'train_loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Item Id embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in nn_dict.keys():\n",
    "    if 'y' not in key: del nn_dict[key][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dense():\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    shop_id_in = Input((1,), name = 'shop_id_in')\n",
    "    shop_id = Embedding(60,10)(shop_id_in)\n",
    "    shop_id = Reshape((10,))(shop_id)\n",
    "    layers.append(shop_id)\n",
    "    \n",
    "    itcat_id_in = Input((1,), name='itcat_in')\n",
    "    itcat_id = Embedding(84,12)(itcat_id_in)\n",
    "    itcat_id = Reshape((12,))(itcat_id)\n",
    "    layers.append(itcat_id)\n",
    "    \n",
    "    month_in = Input((1,), name='month_in')\n",
    "    month = Embedding(12,4)(month_in)\n",
    "    month = Reshape((4,))(month)\n",
    "    layers.append(month)\n",
    "    \n",
    "    year_in = Input((1,), name='year_in')\n",
    "    year = Embedding(3,2)(year_in)\n",
    "    year = Reshape((2,))(year)\n",
    "    layers.append(year)\n",
    "    \n",
    "    date_block_in = Input((1,), name='date_block_in')\n",
    "    date_block = Dense(1)(date_block_in)\n",
    "    layers.append(date_block)\n",
    "    \n",
    "    shop_id_enc_in = Input((4,), name='shop_id_end_in')\n",
    "    shop_id_enc = Dense(4)(shop_id_enc_in)\n",
    "    layers.append(shop_id_enc)\n",
    "    \n",
    "    item_id_enc_in = Input((4,), name='item_id_end_in')\n",
    "    item_id_enc = Dense(4)(item_id_enc_in)\n",
    "    layers.append(item_id_enc)\n",
    "    \n",
    "    itcat_id_enc_in = Input((4,), name='itcat_id_end_in')\n",
    "    itcat_id_enc = Dense(4)(itcat_id_enc_in)\n",
    "    layers.append(itcat_id_enc)\n",
    "    \n",
    "    month_id_enc_in = Input((4,), name='month_id_end_in')\n",
    "    month_id_enc = Dense(4)(month_id_enc_in)\n",
    "    layers.append(month_id_enc)\n",
    "    \n",
    "    year_id_enc_in = Input((4,), name='year_id_end_in')\n",
    "    year_id_enc = Dense(4)(year_id_enc_in)\n",
    "    layers.append(year_id_enc)\n",
    "    \n",
    "    shop_item_lag_in = Input((11,), name='shop_item_lag_in')\n",
    "    shop_item_lag = Dense(11)(shop_item_lag_in)\n",
    "    layers.append(shop_item_lag)\n",
    "    \n",
    "    shop_lag_in = Input((11,), name='shop_lag_in')\n",
    "    shop_lag = Dense(11)(shop_lag_in)\n",
    "    layers.append(shop_lag)\n",
    "    \n",
    "    item_lag_in = Input((11,), name='item_lag_in')\n",
    "    item_lag = Dense(11)(item_lag_in)\n",
    "    layers.append(item_lag)\n",
    "    \n",
    "    itcat_lag_in = Input((11,), name='itcat_lag_in')\n",
    "    itcat_lag = Dense(11)(itcat_lag_in)\n",
    "    layers.append(itcat_lag)\n",
    "    \n",
    "    item_name_in = Input((5,),name='item_name_in')\n",
    "    item_name = Dense(5)(item_name_in)\n",
    "    layers.append(item_name)\n",
    "    \n",
    "    itcat_name_in = Input((5,), name='itcat_name_in')\n",
    "    itcat_name = Dense(5)(itcat_name_in)\n",
    "    layers.append(itcat_name)\n",
    "    \n",
    "    model = Concatenate()(layers)\n",
    "    model = Dense(1000, activation='relu',name='fc1')(model)\n",
    "    model = Dropout(0.3)(model)\n",
    "    \n",
    "    model = Dense(500, activation='relu', name='fc2')(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "    \n",
    "    model = Dense(150,activation='relu', name='fc3')(model)\n",
    "    model = Dropout(0.1)(model)\n",
    "    \n",
    "    model = Dense(15, activation='relu',name='fc4')(model)\n",
    "    model= Dense(1,name='fc5')(model)\n",
    "    \n",
    "    final_model = Model(inputs = [shop_id_in, itcat_id_in, month_in, year_in, date_block_in, shop_id_enc_in,\n",
    "                                 item_id_enc_in, itcat_id_enc_in, month_id_enc_in, year_id_enc_in, shop_item_lag_in,\n",
    "                                 shop_lag_in, item_lag_in, itcat_lag_in, item_name_in, itcat_name_in],\n",
    "                       outputs = model,\n",
    "                       name = 'nn_enc_dense_pfs4')\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "shop_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 1, 10)        600         shop_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 1, 12)        1008        itcat_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 1, 4)         48          month_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_49 (Embedding)        (None, 1, 2)         6           year_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "date_block_in (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_item_lag_in (InputLayer)   (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_lag_in (InputLayer)       (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_name_in (InputLayer)       (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_name_in (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_46 (Reshape)            (None, 10)           0           embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_47 (Reshape)            (None, 12)           0           embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_48 (Reshape)            (None, 4)            0           embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)            (None, 2)            0           embedding_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 1)            2           date_block_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 4)            20          shop_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 4)            20          item_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 4)            20          itcat_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 4)            20          month_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 4)            20          year_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 11)           132         shop_item_lag_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 11)           132         shop_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 11)           132         item_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 11)           132         itcat_lag_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 5)            30          item_name_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 5)            30          itcat_name_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 103)          0           reshape_46[0][0]                 \n",
      "                                                                 reshape_47[0][0]                 \n",
      "                                                                 reshape_48[0][0]                 \n",
      "                                                                 reshape_49[0][0]                 \n",
      "                                                                 dense_113[0][0]                  \n",
      "                                                                 dense_114[0][0]                  \n",
      "                                                                 dense_115[0][0]                  \n",
      "                                                                 dense_116[0][0]                  \n",
      "                                                                 dense_117[0][0]                  \n",
      "                                                                 dense_118[0][0]                  \n",
      "                                                                 dense_119[0][0]                  \n",
      "                                                                 dense_120[0][0]                  \n",
      "                                                                 dense_121[0][0]                  \n",
      "                                                                 dense_122[0][0]                  \n",
      "                                                                 dense_123[0][0]                  \n",
      "                                                                 dense_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1000)         104000      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000)         0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 500)          500500      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 500)          0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 150)          75150       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 150)          0           fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 15)           2265        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 1)            16          fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 684,283\n",
      "Trainable params: 684,283\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model_dense()\n",
    "model.compile('Adam', loss = 'mean_squared_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/50\n",
      "1483908/1483908 [==============================] - 121s 81us/step - loss: 2.6986 - val_loss: 2.7007\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.70067, saving model to nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5\n",
      "Epoch 2/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 2.3965 - val_loss: 2.4823\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.70067 to 2.48235, saving model to nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5\n",
      "Epoch 3/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 2.2958 - val_loss: 2.5107\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.48235\n",
      "Epoch 4/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 2.2272 - val_loss: 2.4846\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.48235\n",
      "Epoch 5/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 2.1803 - val_loss: 2.4080\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.48235 to 2.40801, saving model to nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5\n",
      "Epoch 6/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 2.1388 - val_loss: 2.4207\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.40801\n",
      "Epoch 7/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 2.1026 - val_loss: 2.4087\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.40801\n",
      "Epoch 8/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 2.0648 - val_loss: 2.3924\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.40801 to 2.39235, saving model to nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5\n",
      "Epoch 9/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 2.0348 - val_loss: 2.4670\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.39235\n",
      "Epoch 10/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 2.0081 - val_loss: 2.3817\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.39235 to 2.38167, saving model to nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5\n",
      "Epoch 11/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.9822 - val_loss: 2.5252\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.38167\n",
      "Epoch 12/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.9559 - val_loss: 2.3541\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.38167 to 2.35411, saving model to nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5\n",
      "Epoch 13/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.9347 - val_loss: 2.4933\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.35411\n",
      "Epoch 14/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.9076 - val_loss: 2.4631\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.35411\n",
      "Epoch 15/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.8869 - val_loss: 2.4677\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.35411\n",
      "Epoch 16/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.8718 - val_loss: 2.4212\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.35411\n",
      "Epoch 17/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.8517 - val_loss: 2.4661\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.35411\n",
      "Epoch 18/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.8357 - val_loss: 2.4773\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.35411\n",
      "Epoch 19/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.8210 - val_loss: 2.4536\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.35411\n",
      "Epoch 20/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.8030 - val_loss: 2.3924\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.35411\n",
      "Epoch 21/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.7941 - val_loss: 2.4385\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.35411\n",
      "Epoch 22/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.7776 - val_loss: 2.4980\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.35411\n",
      "Epoch 23/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 1.7670 - val_loss: 2.4988\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.35411\n",
      "Epoch 24/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.7475 - val_loss: 2.6203\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.35411\n",
      "Epoch 25/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.7432 - val_loss: 2.4833\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.35411\n",
      "Epoch 26/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.7277 - val_loss: 2.5202\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.35411\n",
      "Epoch 27/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 1.7124 - val_loss: 2.4349\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.35411\n",
      "Epoch 28/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.7026 - val_loss: 2.5364\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.35411\n",
      "Epoch 29/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.6903 - val_loss: 2.4679\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.35411\n",
      "Epoch 30/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.6806 - val_loss: 2.5597\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.35411\n",
      "Epoch 31/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.6665 - val_loss: 2.4648\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.35411\n",
      "Epoch 32/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.6548 - val_loss: 2.5542\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.35411\n",
      "Epoch 33/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.6478 - val_loss: 2.3930\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.35411\n",
      "Epoch 34/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 1.6447 - val_loss: 2.4654\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.35411\n",
      "Epoch 35/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.6354 - val_loss: 2.5277\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.35411\n",
      "Epoch 36/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.6214 - val_loss: 2.4669\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.35411\n",
      "Epoch 37/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.6152 - val_loss: 2.4242\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.35411\n",
      "Epoch 38/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.6029 - val_loss: 2.6010\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.35411\n",
      "Epoch 39/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.5988 - val_loss: 2.5299\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.35411\n",
      "Epoch 40/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.5917 - val_loss: 2.5224\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.35411\n",
      "Epoch 41/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 1.5833 - val_loss: 2.5288\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.35411\n",
      "Epoch 42/50\n",
      "1483908/1483908 [==============================] - 119s 80us/step - loss: 1.5749 - val_loss: 2.5911\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.35411\n",
      "Epoch 43/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.5713 - val_loss: 2.5203\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.35411\n",
      "Epoch 44/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.5622 - val_loss: 2.5698\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.35411\n",
      "Epoch 45/50\n",
      "1483908/1483908 [==============================] - 118s 80us/step - loss: 1.5510 - val_loss: 2.6224\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.35411\n",
      "Epoch 46/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.5491 - val_loss: 2.6051\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.35411\n",
      "Epoch 47/50\n",
      "1483908/1483908 [==============================] - 118s 79us/step - loss: 1.5421 - val_loss: 2.5997\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.35411\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.5357 - val_loss: 2.4998\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.35411\n",
      "Epoch 49/50\n",
      "1483908/1483908 [==============================] - 116s 78us/step - loss: 1.5284 - val_loss: 2.5288\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.35411\n",
      "Epoch 50/50\n",
      "1483908/1483908 [==============================] - 117s 79us/step - loss: 1.5204 - val_loss: 2.5435\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.35411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd7d27cc18>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss', patience = 15)\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_with_dropout_wo_item_pfs4.hdf5', monitor='val_loss', verbose=1, \n",
    "                              save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=2048, epochs=50, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Learning Curve')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAE/CAYAAADVKysfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4VNXWwOHfTu8FAgmkEnoPJNTQmygCgnREQRRRxILlqtfrVa+9gqCCojRFQEEQRJDeS0LoARICKUAK6b3NnO+PiXxBKSGZZJKw3ufJw2TmzDlrQjJz1tlrr600TUMIIYQQQgghRPVkZuoAhBBCCCGEEELcnCRtQgghhBBCCFGNSdImhBBCCCGEENWYJG1CCCGEEEIIUY1J0iaEEEIIIYQQ1ZgkbUIIIYQQQghRjUnSJoQQolZRSv2hlHrE1HEIIYQQxiJJmxBCCKNQSkUrpQaYOg5N0+7VNG1JZexbKeWklJqtlIpVSmUrpc6XfO9WGccTQgghQJI2IYQQNYhSysKEx7YCtgGtgcGAE9AdSAE6l2N/JnstQgghahZJ2oQQQlQ6pdT9SqljSql0pdR+pVS7Uo+9opSKUkplKaXClVIjSj02WSm1Tyn1uVIqFXiz5L69SqlPlFJpSqmLSql7Sz1np1LqsVLPv9W2jZRSu0uOvVUp9aVS6oebvIyHAR9ghKZp4Zqm6TVNS9I07X+apm0s2Z+mlGpSav+LlVLvlNzuo5S6pJT6l1IqAViklDqjlLq/1PYWSqlkpVTHku+7lvy80pVSx5VSfSry/yCEEKJmkqRNCCFEpSpJQL4HngDqAguA35RS1iWbRAE9AWfgLeAHpVSDUrvoAlwA6gPvlrrvHOAGfAR8p5RSNwnhVtsuBw6XxPUmMOkWL2UAsEnTtOzbv+qb8gDqAL7ANOAnYHypx+8BkjVNC1NKeQK/A++UPOdFYLVSql4Fji+EEKIGkqRNCCFEZXscWKBp2iFN03Ql880KgK4Amqb9rGnalZKRq5VAJNeXG17RNG2upmnFmqblldwXo2nat5qm6YAlQAPA/SbHv+G2SikfoBPwhqZphZqm7QV+u8XrqAvEl+sn8P/0wH81TSsoeS3LgWFKKbuSxyeU3AfwELBR07SNJT+bLUAocF8FYxBCCFHDSNImhBCisvkCL5SU+KUrpdIBb6AhgFLq4VKlk+lAGwyjYn+Ju8E+E/66oWlabslNh5sc/2bbNgRSS913s2P9JQVDwlcRVzVNyy8Vz3ngDDC0JHEbxv8nbb7A6L/93HoYIQYhhBA1jEyCFkIIUdnigHc1TXv37w8opXyBb4H+wAFN03RKqWNA6VJHrZLiigfqKKXsSiVu3rfYfivwjlLKXtO0nJtskwvYlfreA7hU6vsbvZa/SiTNgPCSRA4MP7dlmqY9fpvXIYQQopaTkTYhhBDGZKmUsin1ZYEhKZuulOqiDOyVUkOUUo6APYZE5iqAUmoKhpG2SqdpWgyGcsM3lVJWSqluwNBbPGUZhkRqtVKqhVLKTClVVyn1mlLqr5LFY8AEpZS5Umow0LsMoawABgFP8v+jbAA/YBiBu6dkfzYlzUy87vClCiGEqOEkaRNCCGFMG4G8Ul9vapoWimFe2zwgDTgPTAbQNC0c+BQ4ACQCbYF9VRjvRKAbhtLHd4CVGObb/YOmaQUYmpGcBbYAmRiamLgBh0o2exZD4pdesu+1twtA07R4DK+/e8nx/7o/DhgOvIYhqY0DXkI+u4UQ4q6jNK2yqk6EEEKImkUptRI4q2naf00dixBCCPEXuVonhBDirqWU6qSUalxS6jgYw8jWbUfHhBBCiKokjUiEEELczTyANRja+V8CntQ07ahpQxJCCCGuJ+WRQgghhBBCCFGNSXmkEEIIIYQQQlRjkrQJIYQQQgghRDVmsjltbm5ump+fn6kOL4QQQgghhBAmdeTIkWRN0+rdbjuTJW1+fn6Ehoaa6vBCCCGEEEIIYVJKqZiybCflkUIIIYQQQghRjUnSJoQQQgghhBDVmCRtQgghhBBCCFGNSdImhBBCCCGEENWYJG1CCCGEEEIIUY1J0iaEEEIIIYQQ1ZgkbUIIIYQQQghRjUnSJoQQQgghhBDVmCRtQgghhBBCCFGNSdJWSmRiFj/tjzB1GEIIIYQQQghxjSRtpST9/j8Gb+5LUnqOqUMRQgghhBBCCECStus0btoaV5XNwQO7TB2KEEIIIYQQQgCStF3Ho90AAFJO7zBxJEIIIYQQQghhIElbac6eZNh40jAjjCvpeaaORgghhBBCCCEkafs7s0Y96Gx2lo0nLps6FCGEEEIIIYSQpO3vHJv3wVVlc+LoQVOHIoQQQgghhBCStP2Db3cAXJIOE5eaa+JghBBCCCGEEHc7Sdr+zsWXYoeGdDE7w4YT8aaORgghhBBCCHGXk6Tt75TCwr8nwRYRbDgu89qEEEIIIYQQpiVJ2434BuOipZOfcJaLybLQthBCCCGEEMJ0JGm7Eb8eAHQxO8uG41dMHIwQQgghhBDibiZJ243U8QcHD+51jJJ5bUIIIYQQQgiTkqTtRpQC3+501E5zLjGTyMQsU0ckhBBCCCGEuEtJ0nYzfsHYF1zFTyWyXkbbhBBCCCGEECYiSdvN+BrmtY2vH8uGE1fQNM3EAQkhhBBCCCHuRpK03Uy95mDnxkD781y4msOZeCmRFEIIIYQQQlQ9SdpupmRem2/2cczNFBtOSBdJIYSoSinZBSzed5HCYr2pQxFCCJPT6zUW7Ioi4O0/GTZvL2+tP83Gk/EkZeabOjRRBSxMHUC15tcD8zO/MdS3mA0n4nnpnuYopUwdlRBC3BVeX3uKP04loNfg0R6NTB2OEEKYzJX0PF5YdZwDF1Lo2dSNIp2enw7HsmhfNAA+dewI8nUl0M+VTn51aFLPATMzOWetTW6btCmlvIGlgAegB77RNG3ODbbrA8wGLIFkTdN6GzdUE/ANBgzz2tZebMTJyxm083IxcVBCCFH77TiXxB+nEnC0tmDu9khGBXnhZGNp6rCEEKLK/X4inlfXnKBYr/HRg+0YHeSFUooinZ7TVzIJjU4lNDqN3ZHJrDl6GQBnW0sCfV0J9HUlyNeV9t4u2Fiam/iViIooy0hbMfCCpmlhSilH4IhSaoumaeF/baCUcgG+AgZrmharlKpfSfFWrfqtwMaFAP1pLMz82XAiXpI2IYSoZPlFOv677jSN69nz0aj2PPj1fr7ZdYEX72lu6tCEEKLKZOUX8eZv4awOu0SAtwuzxwbg52Z/7XFLczMCvF0I8HbhsZ6gaRoxKbmExqRxJCaVkOg0tp9NKtlW0cbTmSBfV1p4OOFqb4mLnRUutpa42lnhbGspI3PV3G2TNk3T4oH4kttZSqkzgCcQXmqzCcAaTdNiS7ZLqoRYq56ZGfh2x/rSAXo2nWK40nFvCymRFEKISvTVzihiU3NZ/lgXAn1dGdq+IQv3XmBSN1/cnWxMHZ4QtcrGk/E0crOnZQMnU4ciSjkSk8ZzK49yOS2PZ/o3ZWa/Jlia37oVhVIKPzd7/NzsGRXoBUBaTiFHYtKuJXJL9sdQqPvnPGGlDKNzrnZWuNhd/6+rnSHBc7WzwsPZho4+LnIubAJ3NKdNKeUHdAAO/e2hZoClUmon4AjM0TRt6Q2ePw2YBuDj43Pn0ZqCbzCc28ioQHNmnMsjLDadQF9XU0clhBC10sXkHObvjGJ4QEO6N3ED4KVBzdl0Kp7ZWyN5f2RbE0coRO0Rk5LDjOVh2Fma893kTnT1r2vqkO56xTo9c7efZ96O8zRwtmHVE90I8qtT7v252lsxoJU7A1q5A1BQrCM+PZ+03ELSc4tIzyskLaeI9NxC0nKLrt2fmJnPuYQs0nILyS3UXbfPZ/s35fmBzSr0OsWdK3PSppRyAFYDz2malnmD/QQC/QFb4IBS6qCmaRGlN9I07RvgG4CgoKCasfCZn2FeW1+7SKzMndlw4ookbUIIUQk0TeONdaewtjDj3/e1vHa/T107JnbxZdnBGKb2aEST+g4mjFKI2uOHgzGYK4W7kw2TFx1mwaQgejerZ+qwqsTeyGRc7Cxp4+ls6lCuiUnJ4bmVxzgam87Ijp68Naw1jkaey2ttYW4YjcP+9huXKCjWkZFbRFpuEV/tPM8X2yPp0qjOtQtromqUqeW/UsoSQ8L2o6Zpa26wySVgk6ZpOZqmJQO7gfbGC9OEPNqBtRN2lw/Su3k9Np6MR6+vGfmmEELUJL+fjGdPZDIvDGpG/b+VQc7s1wRbS3M+3nzWRNEJUbvkFepYGRLHPa09+Hl6Nxq5OfD4klD+PJ1g6tAqlaZpfLYlgoe+O8So+fvZFXHV1CGhaRo/h8Zx35w9RCVlM3d8Bz4bE2D0hK28rC3Mqe9kQ3MPR94b0RZ/N3ueXXmMq1kFpg7trnLbpE0Zila/A85omvbZTTZbB/RUSlkopeyALsAZ44VpQmbm4NMVYvZxf7sGJGYWEBKdauqohBCiVsnKL+Lt9eG0bujEQ119//F4XQdrnujlz+bTiRyJkfdgISrqt+OXycwv5uFuvtR1sGbF411p2dCJJ38MY/3x2rk2bX6Rjqd/OsoX2yIZ2cHzWqK62YSJanpuITOWh/HSLydo6+XMpud6MbR9Q5PFczv21hZ8ObEjmXlFzFp1TAYyqlBZRtqCgUlAP6XUsZKv+5RS05VS0wE0TTsDbAJOAIeBhZqmnaq0qKuabzAkRzDAR2FjacaGE/GmjkgIIWqV2VsjuZpdwDsPtMHiJpPtp/ZsRD1Ha97feBZNkxMFIcpL0zSW7I+hubsjnRsZ5ks521nyw9TOBPq48uyKo/wcGmfiKI0rKTOfsQsOsPGkoancp2Pas+LxrrRq6MRTP4ax7tjlKo9p//lkBs/ew5bwRF65twU/PtaVhi62VR7HnWrh4cSbw1qzJzKZr3dFmTqcu8ZtkzZN0/ZqmqY0TWunaVpAyddGTdPma5o2v9R2H2ua1krTtDaaps2u3LCrWMl6bfbxh+jXoj5/nIqn+Aadd4QQQty58CuZLN4fzfjOPnTwufmcYTsrC54b0JTQmDS2nqkdTYqFMIWw2DTC4zOZ1M33ui6AjjaWLH60E8FN3HjplxMsOxhjwiiN59TlDIZ/uY/IpGwWPBTIE70bo5QyJKolXWqfW3mMlSGxVRJPQbGO9zaeYeJ3h7CzNufXp4KZ3rsx5jWo5f64Tt4Mbd+Qz7ZESAVaFSnTnLa7XsMAsLSH6H3c364hydmFHLoov6BCCFFRer3Gf9adwtnWkpfLsA7b2CBv/N3s+XDTWbl4JkQ5LT0Qg6O1BSM6eP7jMTsrC759OIgBLevzn7Wn+Hb3BRNEaDybTycwev4BAH6e3o1BrT2ue9zB2oIlUzrTs2k9/rX6JIv2XazUeE5fyWD4vH18s/sCE7v48PvMntWqGUpZKaV4b0QbvFxteeano6TlFJo6pFpPkrayMLcE784Qs4++zetjZ2XOhhO1s95bCCGq0s9H4jgSk8ar97bAxc7qtttbmJvx8uDmnE/KZnXYpSqIUIja5WpWARtPxvNgoBf21jduIm5jac7XDwUypG0D3t14hi+2Rda4kmRN0/h6ZxTTfzhCMw9H1s0IpnXDGydHtlbmfPtwIINaufPW+nC+3HHe6PEUFuv5fEsEw+ftIyWnkO8eCeKdB9pia2Vu9GNVFUcbS76c0JGU7EJe/Pl4jfsdqWkkaSsrv2BICse2OIMBLd3541QCRXKVVwghyi01p5D3/zhLJz9XHuzoVebn3dPagw4+Lny2JYK8v60fJCom6mo2o77ez4GoFFOHIirJisOxFOk0JnX7Z8Of0izNzZgzLoCRHT35bEsEH246V2NOyguKdbz0ywk+3HSWIW0bsHJa1390pP07awtzvpzYkeEBDfl48zk+3my8ubOnrxjKM+dsi2RY+4Zseb4X/Vu6G2XfptbG05nX7mvBtrNJfLe3ckcp73aStJWVbw/DvzH7ub9dA9Jzi9h3Ptm0MQkhRA320aazZOUX884DbTG7g7kcSilevbcliZkFLNovJwnGkplfxONLQwmNSWPG8jCupOdV6fEzcot4dc0JzidlV+lx7ybFOj3LD8fSs6kbjevdfr1DC3MzPhnVnoldfJi/K4q31odX+26BqTmFTFp4mF+OXOLZ/k2ZO74DNpZlG82yNDfjszEBjOvkzZc7onh7Q3iFErfCYj2ztxpG15KzC/j24SA+GxtQpqqCmuSR7n4MauXOB3+c5VhcuqnDqbUkaSsrz45gYQMx++jdvB6O1hbSRVIIIcrpSEwaK0LimNqjEc09HO/4+Z0b1WFAy/p8vTNK5lIYgU6v8dyKY8Sm5PLByLYUFut58scwCoqrZiSzSKfnqeVH+OlwHB9tkrX4KsvWM4nEZ+Qz6QbLatyMmZninQfa8FiPRizeH82ra06iq6aJW2RiFsO/3MuxS+l8Mb4Dzw9sdl2jlbIwN1O8P7ItU4L9WLSv/K83/Eomw7/cx+ytkQwtGV0b2Kp2jK79nVKKj0e1x93JhqeXh5GRV2TqkGolSdrKysIavDpB9F6sLcwZ2NqdzacTquwDTQghaotinZ7X157Cw8mGZ/s3Lfd+Xh7cgpyCYuZVwvyTu83nWyLYfjaJ/w5txbjOPnwyuj3H49J5e314lRz/fxvC2Xc+hY4+Lmw5kyijbZVkyf4YPF1s77g0TynFv4e05Jl+TVgZGsesVceq3RSRneeSGPnVfvIK9ayc1pVhFVjrTCnFG/e3YkbfxqwIMbzesjY+KtIZRteGzdt7bXTt81o4uvZ3znaWzJ3QgYSMfF5ZfaLalNIW6/ScS8jilyOXWLinZjfVufEMVHFjvsGw60PIS2dou4asCbvMnohkBtTSKydCCFEZlhyI4Ux8Jl9P7HjTRghl0czdkVGBXiw7EMPk7n5417EzYpR3j40n45m34zzjOnlfW9h8cBsPpvduzPxdUQR4uzA6yLvSjr/sYAxLD8QwrZc/03r5E/zBdhbuucAHD7artGPejSITszhwIYWXBzcvV2t5pRSzBjXHxsqcjzadI79Ix9zxHbGyMP31/yX7o3lr/Wmaezix8JEgPI2w1plSipfuaYGdlQUfbza83i/Gd8Da4ualluFXMnnx5+OEx2fyQEBD3hzWutYna6V19HHl5cHNeW/jWX44GMOkbn5VevwinZ7IxGxOXc7g1JUMTl7O4Ex8JvlFhoTbzcGKqT0a3fHoa3UhSdud8AuGXRrEHiS4ySCcbS3ZcOKKJG1CCFFGCRn5fPbnOXo3q8fgNh63f8JtPD+wGeuOXeGzLRF8PjbACBGaXkh0KjOXH+WFQc0qNVkCOBOfyQurjtPRx4W3hre+7mTmxUHNOHEpndfXnqJlA6dKaUu+/3wyb/52mr7N6/GvwS0wN1OMDvJiVcglZg1sdtvmEaLslh6IwcrcjLEV/J16qk8TbC3NeWt9ONOWhTL/ocAyzxkztiKdnrfXh7PsYAwDWrozZ1xAhS4E3ciMvobX+/aGcKYtPcL8hwL/0fGxSKfnqx1RzN0eiYudFQsmBXJP64q/v9VEj/Xw50BUCv/bcIaOvq437dhZUYXFeiISszh5OcOQpF3O4ExCFoXFhgTN3sqc1p7OTOjsS1svJ9p6OtPIzaHGJmwgSdud8eoE5lYQsxer5oMZ3NqDDSeukF+kM9kblhBC1CTv/B5OkV7j7b8lCOXVwNmWKcGNWLA7isd6Nqq0E4SqkpZTyDM/HSUpK5+XfjlBRl4Rj/X0r7RjTVsWipOtBfMfCvzHCIKFuRlfjO/A0Ll7efLHI6x/uodRRw2ik3N48scw/N3s+WJ8h2ujP4/18Gf5oVgW74/m5cEtjHa8ylSs05ORV0RdB2tTh3JDWflFrAm7xP3tGxglxinBjbCxNOe1X08ydsEBujdxw93RmvpONrg7WVPf0Yb6Tta3HJW6U8U6PWm5RaTkFJCSXUhydgE/h15i7/lknujlz8slSX9leLRHI+yszHn115NMXnSY7yZ3wqEkOTwTbxhdO30lk+EBDXlzaGtc7e+e0bW/MzNTfDomgHvn7Obp5UdZP7PHtZ9VRWTkFrHpdDzH4tI5eTmDcwlZFOkMJZiONha0aejMI918aePpTBtPZxrVtb+jBlc1gSRtd8LSFjwDIWY/APe3b8DK0Dh2nkticJsGJg5O1CQZeUV8viWCp/s1wa2afsgLYWx7Iq+y4UQ8zw9ohm9de6Pt98k+jfnpcCwfbjrH0kc7G22/VU3TNF5efcJwMjq9O9/vvcg7v58hNaeQl+5pbtQrxMU6PTOWh5GYUcDKJ27eDt3NwZqvJnZkzIIDPLviGIsmdzLKiVBmfhFTl4RgpuC7RzrhaGN57TE/N3sGt/Fg2cEYnurbxCgnfJUpKSufaUuPEB6fyYcPtmVEh7IvX1FVfj16mZxCHQ8bsVxtfGcf7KzM+eTPcyzcc+HaCXRprnaW1xI491IJnbuTIcGr72iNTq+RnF1ISnYBKTmGf5NLkrKU7MJrSVpqbiF/nyZlZW7GRw+2Y0ynyh2RBhjX2QdbK3NmrTrOQwsP8d0jQfx4KJa52yNxtrW8q0fX/q6OvRVfjOvA+G8P8tqak8wZF1Cu9y9N0zh0MZUVh2P541QCBcV6nG0taevpzKM9GtHW05k2DZ3xqWNX6xK0G6ne74TVkW8w7P0cCrLo5l+XuvZWrD8RL0mbuCPzd0WxeH80NpbmvHJvzbiSLERF5BfpeGPdafzq2vFEb+OOHDnbWvJ03ya8u/EM+84nE9zErcL7PBKTxrYziTzRqzHOdpa3f4IRLDsYw5bwRF4f0pJAX1cCvF1wtrPkq51RpOUW8c4DbYw2kvDexrPsj0rh41Ht6ODjesttO/i48t+hrXl97SnmbIvk+YHNKnRsnV5j5vKjxKTksmxqF3zq/nMu4hO9GrPxZAIrDsdW2kijMZyJz2Tq4hBScwtp4eHI8yuPczYhi5fvqbxRnzulaRpLD8TQzsuZAG8Xo+57eIAnwwM80es10vOKSMzMJzEzn6TMApKy8knMLDDcl1VAVFIySVkFFJehE6OjjQVuDta4OVjh7+ZAJz8r6pZ87+ZgTV17w/cezjZVmtQPD/DE1tKcp5cfpdsH2yks1jOsfUPeGnZ3j67dSBf/ujw/oBmfbokguEldxnbyKfNzk7LyWX3kMitDYolOycXRxoIxQd6M7eRN64ZONbrEsSIkabtTfsGw5xOIO4RFkwEMbuPBmrDL5BYWY2clP05xe0lZ+SzeF42Zgp8Ox/Js/6b/qI8Xorb5ZvcFLibnsPTRzpVSTj6pmy+L90fzwR9nWTcjuNxXXY/EpDJ7ayR7Ig3rcIbFprHk0c5GLfO6kfArmbzz+xn6Nq/H1B6NAEPr8XcfaIOrnSVf7ogiI6+Qz8cGVDiW1Ucu8f2+i0zu7lfmOXMTu/hwNDadOdsiae/tTL8W5Z/L/d7GM+yKuMr7I9vSrXHdG27T3tuFrv51+G7vRR7u5lctml383dbwRJ5ZcRRHGwt+md6d5h6OvLX+NAt2XSAiIYs54zvgZFM1Cf+tHIhK4XxSNp+Mbl9pxzAzU9Sxt6KOvRUtGzjddDu9XiM1t9CQ2GUVkJSZj7mZGXUdrHCzt8bN0bCPyv57q4hBrT1Y+EgQn2+N4Ile/nLR/hae6tuEgxdT+O9vpwnwdr3l8i7FOj27I6+y4nAc284modNrdG5Uh2f6N+XeNg3kPAlp+X/nvDqDMofofQAMadeAvCId288mlXuXOQXFrAqN450N4eyPSq62658I4/h6ZxSFOj0fjGxHRl4Rvx69bOqQhKhUMSk5zNtxniFtG9CrWb1KOYaNpTkvDGrGycsZbDh552tohkSn8tDCQzz49QHCr2Ty6r0t+GBkWw5eSOWV1ScrtX11bmExT/8UhoutJZ+Mbn/dVeS/Oti9PqQlG08m8NiSUHIKist9rGNx6bz660m6+dfl30Nalvl5SineHdGGVg2crq3nVh4rQ2L5bq8hYRzf+dZX3p/o3Zj4jHzWH79SrmNVFk3T+GZ3FI8vC6VxPQd+e7oHbTydsTQ3450H2vK/B9qwJzKZEV/u42JyjqnDZemBGFztLLm/nemTCzMzhZuDNa0bOtO3eX3GdvJhVKAXfZvXp62XMw2cbat1wvaXXs3q8etTwZKw3Ya5meLzsQE4WFvy9PIwcgv/+d4Vl5rLp3+eo8eHO3h0cShhsWk81rMR217ozaonujGyo5ckbCWUqdZRCAoK0kJDQ01y7Ar7tj+YmcPUP9HpNbq+v41AH1fmTwos8y40TeNITBqrQuPYcCKe3EId5mYKnV7D3cmaoe0aMjzAkzaed+8wcG10JT2PPh/vZEQHTz54sC1DvthLsV7P5ud6yf+zqJU0TePRxSEcvpjKthf64OFced0AdXqNIV/sIbdQx9ZZvcs0OnP4YipztkWw73wKbg5WPNGrMRO7+lyrnJi3PZJP/oxgZr8mvDCoeaXE/fIvx/n5yCV+nNqF7rco7fzlyCX+tfoEbTydWTy50x2XYyVl5TNs7j4szBW/Pd2DOuUo54pNyeX+uXvwdLVjzZPd7+hk6vDFVCYuPEhX/7osmtwJC/Nb//9omsbg2XsA2PRcz2rxHllYrOf1tSdZFXqJ+9p68OnogBv+DA5eSOHJH46g02t8ObEjPZtWzsWK27mSnkePD7fzeC9/Xr237Em6EMa0NzKZSd8fYnSgFx+Nak9BsY4/TyeyMiSOveeTMVPQu1k9xnbyoX/L+lje5r2htlFKHdE0Leh220k9X3n4BcOBr6AwF3MrO+5r48GKkDiyC4pvW1udmJnP6rBL/BJ6iQvJOdhbmTO0XUPGdPKiVQNntp1NZN2xKyw5EM3CvRfxd7NnWIAhgWvkZryJ+8I05m4/j4bGzP5NUEoxJdiPl345wb7zKfRoWvF5OEJUBb1eQ6dp6PQamkap24Z/dZqGXg96TeNAVAo7zl3l9SEtKzVhA8NV3VfubcHkRSEsPxTD5OBGN9320IUUZm+N5MCFFNwcrHl9SEsmdvH9xwn4jL5NiEvNY+7283i72hm94cFvx6+wKvQST/dtcsuEDWBUoBc0iIzPAAAgAElEQVTOtpbMWB7G6AUHWDa1Mw2cy7YeVUGxjid/CCMjr4jVT3YvV8IG4FPXjjnjOjBlcQj/XnuST/82Mngzcam5TP/hCN6udsyb0PG2CRsYRvem9fLnhZ+PszPiKn2b1y9XzMaSllPI9B+OcOhiKjP7NeH5Ac1uWobb1b8uvz3dg8eXhvLI94d5fUgrpgT7VXniufxQLBrwUBffKj2uEKX1aOrG032bMHf7ebILijkQlUJabhGeLrbMGtiMUYFeNDTC2nq1nYy0lUfEn7B8NDy8Dvz7EBKdyuj5B5g9NoAHOnj+Y/PCYj3bzyayKvQSO88lodegs18dRgd5cV/bBjdcUyQjt4g/TsWz7tgVDl5MQdOgnZczw9o3ZGj7hrjL2jU1TkxKDv0/3cWELj68PbwNYGjOEPzBdgK8XfhucicTRyjE9fR6jbnbz/PtngsUFOvQ6TXKU73dwsORDTN7lOlEvaI0TWPCt4c4l5jFrpf6XNeVEAzze+Zsi+DghVTqOVrzRC//GyZrpRXp9Dy6OIT9USksmtzJaCWesSm53PfFHpp7OLJyWtcy/3wOXkjhsSWhONtasmxqZ/zrOdz2Oa+uOclPh2OZN6ED97drWNHQ+XxLBHO2RfLOA22uLch9M9kFxTz41X7iM/JYOyO4TPH+pbBYT++Pd+Bb144V07pVNOxyO5+UzdQlIcRn5PPRg+1u+Fl/IzkFxcxadYzNpxMZE+TF/x5oU2XlfwXF///5svAR+XwRplWs0zNx4SHCYtMY1MqDcZ29CW7sdld0fbydso60SdJWHvmZ8KEv9HoJ+r6GXq/R/YPttPF0uu6N8VxCFqtC4/j16GVScwpxd7LmwY5ejAr0uqMPrYSMfDacuMK6Y1c4eTkDpaCbf12GBzRkcJsGONuafqKzuL1Zq47x+4l49rzc97r22p/9eY65O86z44U++FXBaGp0cg7jvz1IOy9nJnbxpUcTedMU/5SVX8TzK4+z9UwiA1u507S+A2ZKYWamMFcKM2WYn2JuVnJb/XX7+m3MzRR9W9Sv0qUtjselM/zLfTzTrwmzSkoaD0SlMHtrBIcuplLf0ZrpvRszoYtPmZuiZOUXMXr+AS6l5fHz9G63bLZQFoXFekbP38/F5Bw2PtsTL9d/dlC8lVOXM3jk+8MALHm08y0Xvv7hYAyvrz3Fk30a8y8jrXum12tMXRLC3vPJrHqi2007UOr0Gk8sC2XHuassmdK5XBUFC/dc4J3fz7BuRjDtjdz9sCz2RF7lqR/DsLYwY8GkIAJ9b91t8+/0eo3Z2yL5Ylskgb6uzH8okHqOlf/3sPboZZ5beYwlj3amdyXNJRXiThQU6ygo1leLBj3ViSRtlW1Bb7BygCm/A/C/DeEsPRDNjhf7sPPcVX4OjeP4pQwszRUDWrozJsibnk3dKnylOepqNr8du8K6Y5eJTsnFytyMPs3rMTzAkwGt6teICbx3o/NJWQz6fDeP9fTntfuun1eQlJlP8IfbmdjFlzeHta70WGb+dJQt4QnYWVmQmlOITx07JnTxYXSgV7VdGFZUrair2UxbGkp0Si6vD2nJ5O5VX9ZVUTOWh7H9TBKfjmnP4v3RHC5J1p7s05jxncuerJUWn5HHA1/uQ6FYOyO4QuWe7288w4LdF/h6YkfubVu+ZgYXrmYz6bvDZOQV8e3DQTfsxHj4YioTvj1Ij6ZufPdIJ6O2oU/PLWTovL0U6zTWz+xxw8T8gz/OMn9XFG8Pb13uNcKyC4rp9v42ejWtx5cTO1Yw6juz7EA0b64Pp2l9BxY+EnTHyXVpv5+I54Wfj+FqZ8W3DwfdMtE2hpFf7SMtt4hts3rLhTkhqjFJ2irb5n/D4W/hlViwtOFobBojvtqPUqBphnKg0UHePBDQsFJOhDVN4+TlDNYdu8L641dIyiqgs18dFj/aSZYeqIZm/BjGznNJ7PlXvxvOJXluxVG2nkniwKv9/lHOZUynLmdw/9y9zOzXhKf7NWHTqQR+PBTL4YupWJmbcW9bDyZ28aWTn2uNO0kXxrHtTCLPrTiGpYUZX07oeNOW7NVddHIOAz7bRXFJc6cnezdmXDmTtdJOX8lgzPwD+NS15+fp3cq1RtSuiKs88v1hJnTx4b0RbSsUT0JGPpO+O0RMai7zxndgUKnFfa+k5zFs3l6cbCz5dUZwpVRlnLqcwYNf76ejjyvLpna+7sLkmrBLzFp1nIldfHjngTYVek/5cNNZFuyKYnsVVSQU6/T8b0M4Sw7E0L9FfeaM72CU9cBOXc5g2tJQUnML+XhUe4a2r3ip6s2Oc//cvfzn/lbXlpAQQlRPkrRVtrO/w4oJMHkj+AWjaRov/nwCWyszxgR509bTucpOenV6jdVhl3hl9Qm6Na7Ld490qpR1kET5nL6SwZAv9l5XqvV3f5VzvXF/Kx6txA/Yh78/zMlL6ex6ue915QkRiVksPxTL6rBLZOUX07S+AxO7+DCio9ddXX6bmlPIxeRsoq7mcOFqDkU6PX2b16eLf51a191Kr9eYt+M8n2+NoHVDJxZMCsKzhk8MX3v0MtkFxYwK9DLqe+LOc0lMXRJKjyZuLHwk6I5+F5Ky8rlvzh7q2luz7ulgo8SVllPIlMUhnLycwYcPtmNUoBf5RTpGzd9PdHIua2d0p0n9m6+PVFG/HLnEiz8fZ3rvxrxyr6H88khMGuO/OUigrytLp3au8N9LUmY+PT7cwZhOXrzzQMUS3dvJzC/i6eVH2R1xlcd7NuKVe1sadYTyalYBT/5whNCYNJ7u24RZA2/e0KS8Xv7lOOuPx3Pwtf539Xu4EDWBJG2VLTcVPvKHvq9B75dNHQ1gWDD1xV+O06dZPeZPCpRSyWrisSWGdud7/tXvlh+eI7/aR0pOIdtf6GPUE4S/7I9KZsK3h3h9SEse6+l/w21yC4vZcDyeHw/FcPxSBraW5gxr35CJXX1o51X1c0mqQkGxjpiUXC5czeZCsiE5++t2em7Rte0szQ3ztQqK9TjbWjKgpTv3tHanV7N6Nf4iSXZBMbNWHuPP8ERGdPDk/ZFta/xrqmw/HY7l1TUnGd/Zm/dGtC3TRTq9XuORRYcJiU7lt6d70MzdeIlUTkEx0384wp7IZP59X0vC4zNZe+wy304KYkCr8i+EXVb//vUkPx6KZf5DHWnr5cLweXuxt7Zg7VPBd7w0wc28svoEvx69zL5X+lXaHMmYlBymLgklOjmHd0e0YWynW68lV16FxXr+s/YUK0PjGNjKvWQtK+NUyaTnFtLlvW2M7OjF+yMrN8EVQlSctPyvbHZ1wL01RO+tNknbg4FeFBTree3Xk8xcfpQvJ3asdaMBxpRTUMymUwkMadeg0k5Qw2LT2HomiZfuaX7bq51Tghsx86ej7DibZPSTLE3T+HDTORo629yy05udlQVjOnkzppM3Jy9l8OOhGNYdu8LK0DjaejozsYsPwwIa3rAEV6fXyM4vJjO/iIy8IrJKbmfmFZGZX0xmyX15RTpGdvSkk18do77Gsjgel86JyxmGpOxqDheTc7iUlntdR8T6jtb417PnvrYN8Hezp3E9Bxq52ePlakuRTmNP5FU2nU5gS3gCq8MuYWdlTp/m9bintQd9W9SvcROsLybnMG1pKBeSc/jP/a141ARtyWui8Z19iEvN5audUXjXseOpPk1u+5wFuy+wJzKZ90a0NWrCBmBvbcHCR4KYtfI47248A8ALA5tVScIG8MbQVpy6ksmLP5+goYsNBUV6VkwLMlrCBvB4L39Whsax9EAMswY2M9p+/3LoQgrTfziCBiyb2qVSS4OtLMz44MG2tGzgyP9+P8PIr/bx1cSORhkRXRUaR0Gxnoe7SZt/IWoTGWmriI0vQ9hSw7w2C+N9MFXU4n0XeXN9OEPaNWDO2IAqabNd0+QUFDN50WFCotMY0q4Bc8d1qJSJ2g8tPMSZ+Ex2v9z3hks7lFak09Pzwx00rm/Pj491NWocm04lMP2HI3w0qh1jgu5snanM/CLWHr3MDwdjiEjMxtHagkA/V3ILdNclZdkFxbfd119XkrMLihnf2ZtXBrfE2a7yk5zL6Xm8vf40m08nAmBraY5/PXsaudnjX8+BxvXs8XdzoFE9+zJf7S7S6Tl4IYXNpxPYfDqRq1kFWJorgpu4Mbi1BwNauVdpx8Ty2HE2iWdWHMXCTPHlhI63XSdMXE+v13hu5TF+O36FOeMCGB5w8zbwR2PTGD3/APe09mDehA6Vlhjr9BofbT5LfqGON4e1rtIE/Ep6HvfP3Ut6biHfT+5En0pYV+3xpaGERKey/5V+Rp2/vSU8kRk/huFVx5bvH+lUJfPm/rLvfDIzloeRnV/Mw938eLZ/03K/L+r1Gn0+2YmHkw2rpptuiQQhRNlJeWRVCF8Hqx6GqVvAu7Opo7nON7ujeG/jWUZ28OST0e2lc1QpOQXFTFkUwpHYNAa38eD3E/HXzcUwlgNRKYz/9uAtyxH/7ssd5/l48zk2P9eL5h7GuRJfrNNzz+zdKKXY9GzPcifxmqZxJCaNHw/FEpGYhaONBU42ljjZWuJkY2n43tYSp2v/Gu5zLrntYGOBuZkit7CY2Vsj+W7vRVztLPnP/a0Y1r5hpZxcFhbrWbj3AnO3lSxq3q8pIzt64uFkY9Tj6fUaR+PS2HQqgU2nE4hLzcNMQZBfHQa39uCeNh7Van6Ypml8tTOKT/48R0sPJxZMCsS7Tvm74t3NCop1TFp4mGNx6Syb2pku/v8cncnML+K+OXvQNNj4bM9aPccoIjGLpMyCcrX2L4sjMak8+PUB3hza6paLp9+JP07GM/Ono7T2dGbplM5VciHp75KzC/j0zwhWhMTiYmvJC4OaM66T9x2/X+84m8SUxSHMHd+h0pqcCCGMS5K2qpCTDB83hv7/hZ6zTB3NP3yxLZLPtkTc0ZyL2i630JCwhcakMWdcAEPaNuD1taf48VAs745ow8Quxikn0TSNMQsOEJuay66X+pa5/DItp5Cu729jZEdP3h/ZziixrAqJ4+XVJ5j/UCCD23jc/glV5PSVDF5bc5LjlzLo1awe7wxvg09d4yUO+88n8591p4i6msM9rd15Y2jrKkmcNE3jTHwWm04nsPlUAucSswBo6+nMrIHN6NvC+KMPdyKnoJgXfz7OH6cSGB7QkA9GtrvlwtLi9tJzCxn59X5SsgtZ81R3Gpdah1PTNGb+dJQ/TiWw6olud7zGl/inUV/vJz4jn10v9alwJclvx6/w/MpjBHi7sGhKJ5OXN5++ksHb68M5dDGVFh6OvHF/qzsaAZ+86DCnr2Sy71/9sLKQKhshaoKyJm3yF10R9m5QrwXE7DN1JDc0s18TZvRtzE+H43hrfTimStCri9zCYh5dHEJIdCqfjw3g/naG0Z23hrWmb/N6/GftKXacTTLKsXZFXCUkOo2n+zW9o/lyrvZWjOjgyZqwy6TlFFY4jvwiHZ9vjSDA24V7WlfN3Jayat3QmTVPBfPm0FYciU5l0OxdfL0ziiKdvkL7TcjIZ+ZPR5mw8BDFeo1FUzpVaSdEpRStGjoxa2AzNj/fix0v9uGVe1sYfv+WhPD1ziiT/S1GJ+cw8qv9bD6dwOtDWjJ7bIAkbEbgYmfF4smdsTBTTF50mOTsgmuPrQqNY8OJeGYNbCYJm5E80bsxl9Pz+P1kfIX2sybsEs+tOEqgrytLHu1s8oQNDO+LK6Z15euJHckuKGbCwkNMWxpKTErObZ8bk5LDroirTOjsIwmbELWQ/FVXlG93iD0IutvP56lqSileHNScx3o0YvH+aN7/4+xdm7jlFeqYujiUwxcNCduwUmUjFuZmzJvQkZYNnJixPIxTlzMqdCxN0/j0zwi8XG0Ze4fzxwAmB/tRUKznp5DYCsUBsOxADPEZ+fxrcItqOdJqbqaYHNyIrS/0pnezeny46SxD5+4lLDbtjvdVpNOzcM8F+n+6k82nE3huQFM2P9eLvpUwr+ZONHKzZ3rvxmyY2ZP72jbgw01nmbXqOPlFuiqNY+e5JIbN20tiVj5LH+3CYz39q+XvRE3lU9eO7yZ34mpWAVOXhJJXqCMyMYv//naa4CZ1ebJ3Y1OHWGv0b1GfxvXs+Wb3hXJ/pq0KieOFn4/T1b8ui6d0MlrnRmNQSnFv2wZsndWbl+5pzt7zyQz8bDcf/HH2lnOHfzgYg7lSTOhSOR0vhRCmJUlbRfkGQ2E2JBw3dSQ3pJTi30NaMqmrL9/svsDnWyJMHVKVyyvUMXVJCIcupvD52Bs3C7C3tuD7yZ1wsbXk0cUhXEnPK/fx/gxP5OTlDJ7t37RcVztbeDjRvXFdlh2IqdCoU2Z+EV/uPE/vZvWq/QLJDZxtWTApiG8mBZKRV8SDX+/n9bUnycwvuv2TgcMXU7n/i7288/sZuvjXZevzvXluQLNq1bbe1sqceeM78MLAZvx69DLjvjlIUmZ+pR+3WKdn3vZIpiwOwdPVjvVP96i0+UZ3uwBvF+aM68CJS+k8s+IoM386ir2VBZ+PCZB5xUZkZqaY1svfUAZ4PuWOn//joRheXn2CHk3c+H5yJ6M2NDEmG0tzZvRtwo4X+3B/+wbM3xVFn493siokDr3++mQ1r1DHypA47mntgbuTjYkiFkJUJknaKsqvh+Hf6OpZIglcKwEcG+TNF9vP8+WO86YOqcrkF+l4bGkIBy+k8OmY9rfs7ubuZMOiKZ3JK9QxZVFImROG0vR6jc/+jMDfzZ4RHW5+rNuZEtyI+Ix8Np9OKPc+vtl1gfTcIl6658YLeldHg1p7sGVWbyZ392P5oVgGfLqLjSfjb3o1/WpWAbNWHWPMggNkFxTzzaRAvnskyKhz44xJKcXM/k2Z/1BHziVkMWzePk5eqtjI7q0ci0tn2Lx9fPJnBEPbNWT1k92k4Uglu6e1B/8Z0oot4YmcTcjikzHtqS8n0Ub3QAdP6jlas2B31B09b/G+i/z711P0a1Gfbx8OqlYXdm7G3cmGz8YEsHZGMN51bHl59QmGf7mPkOjUa9v8dvwymfnF0uZfiFpMkraKcvSAOo0hZr+pI7klMzPFeyPbMqKDJx9vPsfCPRdMHVKlyy/S8diSUPZHpfDJ6PaM6OB12+c093Dk64cCibqazVM/hN3xSNf6E1c4l5jFcwObVWiCfL8W9fGpY8eifdHlen5SVj7f7b3I0PYNaePpXO44TMHB2oL/Dm3N2hnB1HO05qkfw5i6JJRLabnXttHpNZbsj6bfpztZf/wKM/o2Zuus3gxq7VEjSv4Gt2nAL092w9xMMXrBftYfv2LU/WfmF/HGulOM+GofKTkFfD2xI3PGBVTbEYXa5tEejXjtvha8ObSVyctzaytrC3MeDW7EnsjkMpe0f7v7Am+uD2dQK3fmPxRYIxK20gK8XVjzZHdmjw3galYBo+cf4OnlYVxOz2PJ/hiauzvSuVHVr38phKga0j3SGH6baWj///JFMKveHwLFOj3PrjjG7yfjeXt4ax7u5mfqkCpFfpGOx5eGsvd8Mh+Pas+owNsnbKX9HBrHS7+cYHSgFx+NalemRKBYp2fg57uxtjBj4zM9K1wO9d3ei/xvQzi/PR1MOy+XO3ruG+tOsfxQLFtn9a7S9YaMrVinZ/H+aD7901DW+8KgZgR4u/Df305z+komPZu68daw1viX6tZXkyRnFzB92RFCY9J4pl8TnhvQrEK/N5qmGf6214eTnF3Aw938eGFQMxyrQYMFIYwtI6+I7u9vY0Ard+aM63DLbf9aTmVI2wbMHheAZQ1fvzS3sJj5uy6wYFcUmgaFOj3vPNCGh7rKSJsQNU1Zu0fKZVdj8O1hWGQ78TQ0ME6b9spiYW7G7HEBFBTreWPdaawtzBjb6c4mLWflFxGZlE1EQhbnErOITMzG2sKMJvUdrvsy1YlifpGOacuOsPd8Mh892O6OEzaA0UHexKXl8cW2SLzr2PFM/6a3fc6ao5e5mJzDN5MCjTJ/ZXSQF5/9eY5F+6L5fGxAmZ8Xk5LD8kOxjOvsXaMTNjD8vj7W05/BbTx4Y91p3vn9DAAeTjZ8OaEj97WtGSNrN+PmYM2Pj3fh9V9P8cX285xLzOKzMQG3XYj9RuJSc3l97Sl2RVyljacTCx8JuuNkX4iaxNnWkgldfPh+XzQvDmp+w9JfTdOYsy2S2VsjGR7QkE9Ht6/wMgHVgZ2VBbMGNmNMkBcf/HGWcwlZFSrJF0JUfzLSZgzpcTC7DQz+ALo+aepoyqSgWMe0pUfYHXmVz8bcuHQwv0jH+aRsIhINyVlEQhYRidlcLtWkw9bSnKbuDhQW67lwNYfCUuWEHk42NHV3oHE9B5q6O9CkniGZq+tgXWmvK79IxxPLDK/rwwfbMaYc3Rv/omkaL6w6zpqjl/l87K3LKwuKdfT7ZBd1HaxYNyPYaInEm7+d5sdDMez7V78yz4t5dsVR/jydyK6X+tSquTSaprH5dAKRidlM6dGoWnV7qyhN0/hu70Xe23iGZu6OLHwkCC/Xss09K9Lp+XbPBb7YFom5UrwwqDkPd/OtFSemQtxOfEYePT/cwUNdfXlzWOvrHvurk++8Hed5sKOhasJcGsIIIaoZo420KaW8gaWAB6AHvtE0bc5Ntu0EHATGapr2y52FXIO5eIOLD0TvrTFJm7WFOQsmBTJlUQgvrDpOfpEeJxvLUslZFtEpOfzVoMrSXNG4ngNBfq5McPehubsjzdwd8XK1vTaqVKzTE5eWx/mkbCKTsjiflM35pGxWhcaRW/j/7c3r2FsZEriSRK6ZuyNtvZxxtq3YyFxBsY7pPxxhV8RVPqpgwgaGphEfPNiO+Ix8Xv7lBO5ONnRvfOOue6tC4ricnsd7I427iPkj3f1YciCaHw/F8vzAZrfd/vSVDNYdM8zxqk0JGxj+Pwa3acDgNqaOxPiUUjzW058m9R2Yufwow+ftY8GkQIL8bj0/JTQ6ldd+PUlEYjaDW3vw32GtaOBcNevRCVEdNHC2ZXiAJytD4ni2f1Nc7a0AQ8L2wR9nWbD7AuM6efPeiLbSwVMIUaPddqRNKdUAaKBpWphSyhE4AjygaVr437YzB7YA+cD3t0vaatVIG8CvT0LEJngpCsxqzhXu3MJiHvn+MCHRhnWxzBT4udnT3N2Rpu6ONHd3pLmHA7517cs9B0Cv14jPzDckc4lZRF3NJjIxm8ikbDLyDB0alYIm9Rzo4ONCRx9XOvi40rS+Q5k/ZAuKdUxfdoQd567ywci2jOtsvHVqMvKKGPX1fhIy81nzZHeaujte93h+kY5eH+3At64dq57oZvRyvUcXh3DiUjr7XumHtcWt50xOXnSYo7Hp7H65b4WTYGEa55OyeWxJCJfT83j3gbaM6fTPiw/puYV8uOksPx2Ow9PFlreGtWZAq+q1eLoQVeVcQhb3zN7NCwObMbN/UzRN4+0N4SzaF82krr68Nay1JGxCiGrLaCNtmqbFA/Elt7OUUmcATyD8b5vOBFYDne483FrALxiOL4erZ8G9lamjKTM7KwuWPNqZfedTaOhiQ+N6DkbvqGVmpvB0scXTxZbezepdu1/TNJKzCzmXkMXR2DSOxqWzJTyRVaGXAHC0tqC9twsdfVzo4ONKBx8XXOys/rH/gmIdT/4Qxo5zV3lvhHETNjDMm/h+cidGfLWfyYtC+HVGd+o7/v8o1g8HY0jKKmDu+A6VMr9qSrAfk747zIbj8Tx4i/l5By+ksPPcVV67r4UkbDVYk/oOrJ0RzNPLj/Ly6hOcS8zi1XtbYGFuhqZprD12mXc2nCE9r4hpvfx5tn/Tcs2BE6K2aO7hSN/m9Vi8P5rHevrz7sZwfjgYy5RgP964v1WNnvcqhBB/uaM5bUopP2A30EbTtMxS93sCy4F+wHfAhhuNtCmlpgHTAHx8fAJjYmIqEnv1knoRvgiAe96Hbk+ZOpoaS9M0olNyCYtJ42hcGkdj0zmbkIWupE7T382egGujcS74uzkw86cwtp5J4t0RbZjYpfI6Z524lM7YBQdp6u7AimldsbOyILugmF4f7aB1QyeWTe1SKcfVNI1Bn+/G2tKM9U/3uOEJiKZpjPx6PwkZ+ex4sU+Na2Ut/qlYp+ed38+weH80vZrV48VBzfhw01n2nU8hwNuF90a0pVVDJ1OHKUS1cPBCCuO+OUhzd0fOJWbxRC9/Xrm3hSRsQohqz+jdI5VSDhhG0p4rnbCVmA38S9M03a3eIDVN+wb4BgzlkWU9do3g6geeQbDrQ2g51DDPTdwxpRSN3Oxp5GZ/bVQpt7CYE5cyCIs1JHG7I66yJuwyAOZmCp1e450HKjdhA2jn5cLc8R2YtiyUZ346yoJJQSzed5HUnEJmlWG+WXkppZgc7Me/fz1FaEwanW4wz2lLeCJHY9P58MG2krDVEhbmZrw5rDXN3B15Y90phkVcxdHGgv890IYJnX2koYIQpXRpVIf23i4cj0tnZr8mzBrYTBI2IUStUqaRNqWUJbAB2Kxp2mc3ePwi8Ne7oxuQC0zTNG3tzfZZ6+a0AaREwYLehvLIyRvBXEqWKoOmaVxKyyMsNo3jcRkE+roypF2DKjv+0gPRvLHuNGOCvNh0KoHOjeqw8JHKrQrOK9TR9f1tBDepy1cTA697TKfXGDx7NzpN48/neknXwFro8MVU/jydwLRe/rWuwYwQxnLhajZn4rOq9PNACCEqypjdIxWGksczN0rYADRNa1Rq+8UYyiNvmrDVWnUbw9DZsHoq7HwP+r9h6ohqJaUU3nXs8K5jx/CAql+X5uFufsSl5vLtnosAzBrYvNKPaWtlzrjO3izcc5HL6Xl4uvx/h8A1YZeITMrm64kdJWGrpTo3qkPnRrfuJCnE3c6/ngP+9RxMHYYQQlSKspzhBQOTgH5KqWMlX/cppaYrpaZXcnw1T9tR0GES7PkMonaYOhpRSV69tyWTuvryRG//KrcTpScAACAASURBVJtX9HA3P8Aw0veX/CIds7dG0t7LmcFtPKokDiGEEEIIUbXK0j1yL/9f+nhbmqZNrkhAtcK9H0HcYVgzDZ7cB//X3n3H2VXV+/9/rekzmZKeTCY9BJJAQoDQpAekRkCkRBEEC1dRBBt4rz/r1d/X+9CvXrlSLiKi0qsiIIgUEZCSQEgCCUkIIZn03idlsr9/rBPOpE/IzOwzM6/n47Eee5+99znzOWE/mLyz1l6rvHvaFamJ5eUF/vPcll0wrKZjKacd2IN7Xo3rEZUVFXDHy+8zd8V6fnb+CJ/fkCRJaqMcS9Ucisrggtthwyp4+N9gy5a0K1IbcfkxA1i5fhMPvzGX1XWbuOHZGRw3uCsf2W/ni35LkiSp9TO0NZcew+D0n8K7z8BLv0q7GrURo/p14qCaSm5/cRa/eX4my9dt4rrTh6RdliRJkpqRoa05HXYZDDsXnv7POFxS2kchBC7/yACmL1rDDc+9y5gR1RxUU5V2WZIkSWpGhrbmFAKcfT1U9YYHPgfrl6ddkdqAMQdX07W8GIBvnNr8M1dKkiQpXYa25lZSBef/DlbPg0eugkasiyftTnFBPv//xw/iJ+cexICuHdIuR5IkSc3M0NYSeh8GJ38fpvwFXrs17WrUBpx6YE/GHtE37TIkSZLUAgxtLeXor8B+H4UnvwMLJqVdjSRJkqRWwtDWUvLy4OM3Q2knuP9y2LAm7YokSZIktQKGtpbUoSt84jewdAb89dq0q5EkSZLUChjaWtqA4+GEa2HCnfDmvWlXI0mSJCnHGdrScPy10Pcj8OjXYMmMtKuRJEmSlMMMbWnIL4BP3AoFxfDAZbB5Q9oVSZIkScpRhra0VNXAuTfFmST/9t20q5EkSZKUowxtaTrgdDjqSnj1f2HqY2lXI0mSJCkHGdrSdsoPoHok/OlKWDEn7WokSZIk5RhDW9oKiuH822BLPTz4Odi4Lu2KJEmSJOUQQ1su6DIIzvkfmPMq3HEerF+RdkWSJEmScoShLVcc+HG44HaoHQe3nwWrF6ZdkSRJkqQcYGjLJQeeCxffB8veg9tOg+Wz0q5IkiRJUsoMbblm0Gi49M+wfjn89jRY+HbaFUmSJElKkaEtF/U5HD77BIQAvzsjPusmSZIkqV0ytOWq7kPhs09CWWf4wzkw4+9pVyRJkiQpBYa2XNapXwxuXQbBXWNh8oNpVyRJkiSphRnacl15d7jsMeh9ODzwOXjtt2lXJEmSJKkFGdpag5IquOQh2P80eOzr8PzPIEnSrkqSJElSCzC0tRaFpXDRHTDiInjmx/Dkd2DLlrSrkiRJktTMCtIuQHshvxDOvRlKO8PLN8RlAc7+H8j3P6MkSZLUVvm3/dYmLw9O/z9xVslnfwJ1K+D822JPnCRJkqQ2x+GRrVEIcMK1cObP4Z2/wh3nQ93KtKuSJEmS1AwMba3ZEV+AT9wKc16G28fAmkVpVyRJkiSpiRnaWrvh58Mn74Ul0+GGI+HNe5xZUpIkSWpDDG1tweBT4Ipnoct+8PC/wR/PhWUz065KkiRJUhPYY2gLIfQJITwbQpgSQngrhHD1Tq65OIQwMdNeCiEc3Dzlape6D4XPPgln/V+Y+zrceDS88Euo35R2ZZIkSZL2QWN62jYD30iSZChwFPDlEMKw7a55DzghSZIRwH8CtzRtmWqUvDw4/PPw5Vdg8Efh7z+AW06E2nFpVyZJkiTpQ9pjaEuSZH6SJK9n9lcDU4Ca7a55KUmS5ZmXLwO9m7pQ7YXKXnEh7ovuhHXL4NZT4PFrYcPqtCuTJEmStJf26pm2EEJ/4BDgld1c9jngrx++JDWZoWNir9sRX4BXb4kTlUx9PO2qJEmSJO2FRoe2EEI58CBwTZIkq3ZxzUnE0HbdLs5fEUIYF0IYt3jx4g9Tr/ZWSSWc+TP43FNQUgX3fBLuvQRWzU+7MkmSJEmNEJJGTA8fQigEHgWeTJLkF7u4ZgTwMHBGkiTT9vSZo0aNSsaN81mrFlW/CV66Hp77LygohlN+AIddHp+FkyRJktSiQgjjkyQZtafrGjN7ZAB+C0zZTWDrCzwEXNKYwKaU5BfCcd+AK/8FvUbCY1+H350Oi6akXZkkSZKkXWhMF8sxwCXA6BDChEw7M4TwxRDCFzPXfA/oAtyYOW8XWi7rMggufQTOvQmWTIObj4Nnfgwb16ZdmSRJkqTtNGp4ZHNweGSOWLsEnvwPmHgvVPSCk78LI8Y6ZFKSJElqZk02PFJtXIeucN4tcPkTUNET/vQluOUEeO/5tCuTJEmShKFNW/U7Gj7/NJx3K6xfDr//GNz9SVgyPe3KJEmSpHbN0KasvDwYcQF85TU4+fvw3j/hxqPiwtxrl6ZdnSRJktQuGdq0o8JSOO7r8NU34NBL4bXfwPWHwIvXw+YNaVcnSZIktSuGNu1aeTcY80v40kvQ5wh46rvw68PhrYchpQlsJEmSpPbG0KY96z4UPv0AXPIwFJXD/ZfBbadBrbN/SpIkSc3N0KbGGzQavvhP+Nj1sHwW3HoyPPBZWP5+2pVJkiRJbZahTXsnLx8O+wxc9Tocfy1MfTwOmXzyO7B6QdrVSZIkSW2OoU0fTnE5jP4OXDUehp8PL98E/z0CHv8WrKxNuzpJkiSpzTC0ad9U1cC5N8JV4+Dgi2DcbfCrkfCXq+MQSkmSJEn7xNCmptF5IJz9P/DVCXH45IS74PpD4U9XwpIZaVcnSZIktVqGNjWtjn3grP8LV0+EI/8NJj8ENxwOD3wOFk1JuzpJkiSp1TG0qXlUVsPp/weumQgfuQre+SvceBTcewnMn5h2dZIkSVKrYWhT8yrvDh/9EXxtMhz/LZj5HPzvcXDXWJg7Pu3qJEmSpJxnaFPLKOsMo/8/uGYSnPQdmPMy/GY0/PE8mP1y2tVJkiRJOcvQppZV2hFOuDaGt1N+CPPfhNtOgz+cC3NeS7s6SZIkKecY2pSO4go49poY3k79MSyYBL89Be68AOa9kXZ1kiRJUs4wtCldRWVxopKr34STvw+1r8EtJ8Ldn4pBTpIkSWrnDG3KDcXlcNzX41IBJ30HZr0ANx8L913qUgGSJElq1wxtyi0llZln3ibC8dfCjGfgxqPhwc/DkulpVydJkiS1OEObclNpRxj9nRjejr0Gpj4ONxwBD38Jls1MuzpJkiSpxRjalNvKOsMpP4jPvB11Jbz1EPzPKHjkKlgxO+3qJEmSpGZnaFPrUN4NTvtJDG9HfAHevBeuPxQe/ZrhTZIkSW2aoU2tS0VPOOO/4KtvwKGXwut/hF8dDHddBO88AVvq065QkiRJalIhSZJUfvCoUaOScePGpfKz1YasrIXxt8Prf4A1C6GyNxz2GTjkEqisTrs6SZIkaZdCCOOTJBm1x+sMbWoT6jfBO3+FcbfBzGch5MMBZ8Coy2HgaMizU1mSJEm5pbGhraAlipGaXX4hDDs7tqXvwuu/hzfuhKmPQqf+cOhn4JBPQ3n3tCuVJEmS9oo9bWq7Nm+IoW3c72DWPyGvEIaOgcMuhwHHQwhpVyhJkqR2zJ42qaAYDvpEbIunxWffJtwJbz0MXfaDwy6Dgz8FHbqkXakkSZK0S/a0qX3ZtB7e/nPsfZvzMuQXwf6nwYixMPijMehJkiRJLcCeNmlnCkvh4LGxLXw7zjo5+QGY8hco6QgHfjye63OkwyclSZKUE+xpk+o3w8znYOI9MOVR2LweOvaDERfBiAuh6+C0K5QkSVIb5JT/0oexYTVMfQzevAfe+wckW6DXoTHAHfQJKO+WdoWSJElqI5ostIUQ+gB/AHoCW4BbkiT51XbXBOBXwJnAOuCyJEle393nGtqU81bNh8kPxh64BZPi2m/7nRwD3AFnQlFZ2hVKkiSpFWvK0FYNVCdJ8noIoQIYD5ybJMnbDa45E7iKGNqOBH6VJMmRu/tcQ5talYVvw6T7YOL9sKoWisph6Nkw4gLofzzk+3ioJEmS9k6TTUSSJMl8YH5mf3UIYQpQA7zd4LJzgD8kMQG+HELoGEKozrxXav16DIMeP4DR34P3X4SJ98ZZKN+8Czp0ixOYDL8Aeh/uBCaSJElqUnvVPRBC6A8cAryy3akaYE6D17WZY4Y2tS15eTDguNjO/DlM/xtMuh/G/x5evQU69s2sDXc+9DjQACdJkqR91ujQFkIoBx4ErkmSZNX2p3fylh3GXYYQrgCuAOjbt+9elCnloMISGHZ2bHWr4gQmkx+AF6+HF34J3YbE8Db8E9B5YNrVSpIkqZVq1OyRIYRC4FHgySRJfrGT8/8LPJckyd2Z1+8AJ+5ueKTPtKnNWrsE3v4TTHoQZr8Uj/U6NA6fPPDjUFmdbn2SJEnKCU05EUkAfg8sS5Lkml1ccxbwFbITkVyfJMkRu/tcQ5vahRVz4K2HYNIDsGAiEKD/sTD8/DiRSVnntCuUJElSSpoytB0L/BOYRJzyH+A/gL4ASZLcnAl2vwZOJ075f3mSJLtNZIY2tTtLpsfwNvkBWDoD8gph8EdjD9wBZ0BhadoVSpIkqQW5uLaUq5IE5r8ZJzCZ/CCsng9FFTD0Yy4hIEmS1I4Y2qTWYEs9zHohrgH39l9gw0ro0D3OQDnigvgsnDNQSpIktUmGNqm12VQXlxCYeG/c1m+ELvvB8AvjM3BdBqVdoSRJkpqQoU1qzdavgCmPwMT7Yk8cCdSMis+/HXQelHdPu0JJkiTtI0Ob1FasnBuffZt0HyyYBCEfBp4Yw9t+H4WKHmlXKEmSpA/B0Ca1RYumxvA26X5YMTse6zkizkK530eh9+FOYiJJktRKGNqktixJYOFkmP5UbHNegaQeSqpg4EmZEHcKVPRMu1JJkiTtQmNDm/8kL7VGIUDP4bEd9/X4DNzM52DGUzD97/D2n+J19sJJkiS1eva0SW1NksRn37YGOHvhJEmScpI9bVJ7FQJUj4jtuG9keuGejQFuRoNeuH7HwMFjYdg5MdBJkiQpJ9nTJrUnW3vh3vlrnNBk6QwoKIEDzowBbtBoyC9Mu0pJkqR2wZ42STtq2At3wrUwdzy8eQ9MfgDeegg6dIODzoeDL4LqkfF6SZIkpcqeNkmweWN8Bu7Ne2DaE1C/EboNgREXwYgLoap32hVKkiS1OU75L+nDWb8c3noY3rwX5rwMBBhwHIwYC8POhuKKtCuUJElqEwxtkvbdspkw8b7YA7f8PSgohaFj4hDKAcdBUYe0K5QkSWq1DG2Smk6SwJxXYeI9MPkhqFsB+UXQ9+i4fMB+J0P3YT4DJ0mStBcMbZKax+YN8P5LcfmAd5+BRW/H4xXVMOjkGOAGnghlndOsUpIkKec5e6Sk5lFQDINOig1g5dwY3mb8HaY+ChPugJAHvQ7N9sLVHAZ5+enWLUmS1ErZ0yap6Wyph7mvZ3rhno5LCiRboKRj7H3bGuIqe6VdqSRJUuocHikpfeuWwcznYMbTMcStnh+PV/WFXiOh1yGZNhJKO6VaqiRJUktzeKSk9JV1hoPOiy1JYNGUOJRy3usw7w2Y8kj22k4DsiGu5lDoOQJKKtOrXZIkKUcY2iS1jBCgx7DYtlq/HOa/GQPc3Nehdhy89dDWN0DXwQ164w6BnsNdZkCSJLU7hjZJ6SntFJ91G3hi9tjaJTBvQgxy896A9/4JE++N50Ie9Dgw856ToN9HoLC0pauWJElqUT7TJin3rV6QDXLvvwhzXoH6jZBfDP2OjgFu0GjocRDk5aVdrSRJUqM4EYmktmvjWnj/X/H5uJnPZteKK+sae+EGjY5LEjhLpSRJymFORCKp7SrqAINPiQ1g1fw4S+XMZ+HdZ2HyA/F41wOyAa7fMVBcnlrJkiRJH5Y9bZLaliSBhW9lAtwz8P5LsLkO8gqhzxHQ92jofTj0HgUduqZdrSRJasfsaZPUPoUAPQ+K7SNXwaY6mPNyZijlc/DCLyGpj9d27BfDW+/DoWYUVI+AguJUy5ckSdqeoU1S21ZYsu0MlRvXwfwJcXmB2tdg9ssw+cF4Lq8wBreaUTHM1RwGnQfGIChJkpQSQ5uk9qWoLC4V0O8j2WOr5sUQN3cc1I6HN+6AV/83nivtnAlwo6D3YVB9CHTokk7tkiSpXTK0SVJlLxh2dmwA9Zth8ZRtg9z0p4DMM8BVfaD6YKgeCb1Gxm15t9TKlyRJbZuhTZK2l18APYfHNuryeKxuVRxWOW9Cdjv10ex7KmsahLhMoKvokU79kiSpTTG0SVJjlFTCgONj26puJSyYtG2Qe+dxPuiRq6jeNsj1PsKhlZIkaa8Z2iTpwyqpgv7HxrbVhtUwf2IMcfPfjEFu2hN8EOS6DYlrxvX7SNxWVqdSuiRJaj32GNpCCLcBY4BFSZIctJPzVcAdQN/M5/08SZLfNXWhktQqFFdA/2Ni22rDGlgwEWb/K64bN/E+GPfbeK7TgBje+meCXMd+zlYpSZK2scfFtUMIxwNrgD/sIrT9B1CVJMl1IYRuwDtAzyRJNu7uc11cW1K7Vb8ZFk6CWS/GEDf7JVi/PJ6rrMnObtnvWOg62BAnSVIb1WSLaydJ8nwIof/uLgEqQggBKAeWAZsbWacktT/5BdDrkNg+8hXYsgUWT4X3X4ztvedh0v3x2rKuMcD1OSL2wnXsE2evLOtimJMkqZ1oimfafg08AswDKoCLkiTZ0gSfK0ntQ14e9BgW2xFfgCSBZTMzIe6l2CM35ZFt31NYBlW9Y4Cr6p0Jc32z+xW9YjiUJEmtXlP8Rj8NmACMBgYBT4UQ/pkkyartLwwhXAFcAdC3b98m+NGS1AaFAF0GxXbopfHYumWwYjasrIWVc2DFnLhdOSdOeLJuyXafkReD29aeue5DY29dr0PjAuOSJKnVaIrQdjnw0yQ+HDcjhPAeMAR4dfsLkyS5BbgF4jNtTfCzJal9KOscW6+ROz+/aX0MdDsEu1qY/TJMui9eF/Kh50Fx+YE+R0Dvw6FTf4daSpKUw5oitM0GTgb+GULoARwAzGyCz5UkNVZhaZy0pOvgnZ9fuxRqX4PaV2HOqzDhLnjtN/Fch+4xvPU5PIa5XofYGydJUg5pzJT/dwMnAl1DCLXA94FCgCRJbgb+E7g9hDAJCMB1SZIs2cXHSZLS0KELHHB6bBBnsFz0dibEZcLcO4/Fc3kF0OOgTE/cEVBzaOyNy8tPrXxJktqzPU7531yc8l+ScszaJVA7LtsbN/d12LQ2nssrjMGtyyDoPDDbugyKz8wZ6CRJ2mtNNuW/JKmd6NB1571x8yfA0nfjjJbLZsYlCTaty77PQCdJUrMytEmSdi6/AKpHxNZQksDqBbAsE+T2FOh6DoeBJ8LAE6DPUVBY0pLfQpKkVs/hkZKkpvNBoJsZQ93SGTD7FZg7DrZshvxi6HtUDHADT4TqkfbESZLarcYOjzS0SZKa34bVcaHwmf+A9/4BCyfH4yVV0P+4GOAGnBBnv3T5AUlSO+EzbZKk3FFcAfufFhvAmsUxvL33D5j5HEx9NB6vqM4GuIEnQGWvlAqWJCl3GNokSS2vvBsMPz82gGXvZQPc9L/Bm3fH4536Q1lXKKmE4soY/kqqGuxntsWVDa7J7BeU2GsnSWoTDG2SpPR1HhDbYZfBli2w6K0Y4OaOh7qVULcKVtbGYZZ1q7JLEexOXiF07AM1h8XW69A4qUphaXN/G0mSmpShTZKUW/Ly4oyTPYfv+pr6zbAxE+A2rIYNq7KBbsPKzP5KWDIdZr0Ik+6P7wv50GNYNsTVHAbdhsSZMiVJylH+lpIktT75BVDaKbbGWDUf5r0ee+7mvg5vPQzjb4/nCsug+uBMkDskbjv1d2ilJClnGNokSW1fZTVUngVDzoqvt2yB5e9lQ9zc8fDqb6B+Qzxf2hlqDs30xmW2FT3Sq1+S1K4Z2iRJ7U9eHnQZFNuIC+Ox+k2w6O0GQe51ePfnkGyJ5yt6ZQLcIdltY3v6JEnaB4Y2SZIA8gvjMMnqg2HUZ+OxjWth/kSY90ZmeOXr2eUJADoN2LZHrvpgKOqQTv2SpDbL0CZJ0q4UdYB+R8e21frlMG9CNsTNfgUmPxjPhbw4sUmvQ6DHgfHZuE79oWM/KC5P4xtIktoAQ5skSXujtBMMOim2rVYv3LY3btoTMOHObd/XoVs2wG0Nc1tbZS/Iy2+xryBJal0MbZIk7auKHnDA6bEBJEnskVv+HiyfBcvfz2xnQe1rcfbKpD77/q1ryjUMcl0PgO5DoKpvfAZPktRuGdokSWpqIUBZ59hqDtvxfP1mWFWbDXINg928P8H6ZdlrC8ug6/5x2GX3IXHbbUjssTPMSVK7YGiTJKml5Rdke9R2Zv0KWDINFk2Bxe/A4inw3vMw8Z7sNQWl0G3/bIjbGuo69nOopSS1MYY2SZJyTWlH6HNEbA3VrcyEuKmwaGrcznoBJt6bvaagBLrs1+DZuX7Z/Y59oaisJb+JJKkJGNokSWotSqp2EeZWZcPc4qmw9F1YNhNmPgub1m17bXmPbQNdw8lRnBBFknKSoU2SpNaupBL6HB5bQ0kCaxdnn5dbMSv7/Nzsl2HyA9nFwyE7IUr3YXHNuZ7DoeeIGOZCaMEvJElqyNAmSVJbFQKUd49t+0AHUL8JVmYmRFmRCXbLZsLCt2DqY0ASryvtDNUjsiGu54g4BDPfv0ZIUkvw/7aSJLVX+YXQeUBs29uwJoa3BRMzbRK8cgvUb4jnC0riAuINg1yPA31mTpKagaFNkiTtqLgc+h4Z21b1m2DJ9GyIm/8mvPUnGH97PB/yoNMA6HZAZpmCzLbr/nEIpyTpQzG0SZKkxskvhB7DYjt4bDyWJLByTibETYRFb8flCqY/BVs2Zd9bUQ1dB8dFwxuGuYqePi8nSXtgaJMkSR9eCHEpgY59YchZ2eP1m+KEJ0veiTNbLpkW25v3wMbV2euKK7MBrutgqOqdeQ6vR2ylnQx1kto9Q5skSWp6+YXQdb/YGoa5JIHV82OAWzwtG+refQbevGvHz8krzE6mUt5j20C3db9Dt7gtLm+57ydJLSinQtumTZuora2lrq4u7VJavZKSEnr37k1hYWHapUiSlBVCXEKgshcMPHHbc3WrYM3CBm3RtttVc2HeG3EZg4ZLFWyVXxwnQinskNmWNtgvg6IOmWNb9xtuy+IQzo59obwn5OW1xJ+GJDVKToW22tpaKioq6N+/P8GhEB9akiQsXbqU2tpaBgzYyYxgkiTlopLK2LoO3v11W+ph3bIdw936ZbBxXVxQfONa2LQ+7q9bBptqM+caHN+V/KI4THPrsM+OfaFj/+x+eQ9DnaQWlVOhra6uzsDWBEIIdOnShcWLF6ddiiRJTS8vH8q7xcZBH+4ztmyBzeuzQW7jWlg1P65Xt2J2pr0P7/w19uw1lF8EVX22DXWdB8RlDzoPjPVJUhPKqdAGGNiaiH+OkiTtRl5eHBpZ1AHoFo/1OHDn125cF2fI3BrkPgh1s+Gdx7cNdYVl0OOguH7d1gXJuw+LwzIl6UPKudAmSZKUU4rK4jIF3Q7Y+fmNa2HpDFgwObuG3aT7Ydxv4/mQH2fHbBjkeo6Ass4t9x0ktWqGtn1QXl7OmjVrdnpu1qxZjBkzhsmTJ7dwVZIkqUUVdYDqg2Pj4nhsy5bYK7c1xC2YBLNegEn3Zd9X2Tsb4qr6QIeucSbMsi5xv6jc5Q4kAYY2SZKkppeXF59z6zwAhp2TPb52ybZBbv5EmPbEzmfDLCiBsq7QoUsmzHXNBLuuDfYzyx1U1jg5itSG7TG0hRBuA8YAi5Ik2enTviGEE4H/BgqBJUmSnLCvhf3wL2/x9rxV+/ox2xjWq5Lvf2wX49WB6667jn79+nHllVcC8IMf/IAQAs8//zzLly9n06ZN/PjHP+acc87Z5WfsTF1dHV/60pcYN24cBQUF/OIXv+Ckk07irbfe4vLLL2fjxo1s2bKFBx98kF69enHhhRdSW1tLfX093/3ud7nooov26XtLkqQc0aErDBod21ab6mDtohjo1i6BdUvic3Jrl8C6pdn9JdPidmczXxZ2gG77Q7ehmaGcQ6D7EKjqa5iT2oDG9LTdDvwa+MPOToYQOgI3AqcnSTI7hNC96cprWWPHjuWaa675ILTdd999PPHEE3zta1+jsrKSJUuWcNRRR3H22Wfv1UQfN9xwAwCTJk1i6tSpnHrqqUybNo2bb76Zq6++mosvvpiNGzdSX1/P448/Tq9evXjssccAWLlyZdN/UUmSlDsKS7KzUDbGxnUNgt1SWFUbFypfPAVmPrvtIuUFpTsPcx37Ocul1IrsMbQlSfJ8CKH/bi75FPBQkiSzM9cvaorCdtcj1lwOOeQQFi1axLx581i8eDGdOnWiurqar33tazz//PPk5eUxd+5cFi5cSM+ePRv9uS+88AJXXXUVAEOGDKFfv35MmzaNo48+mp/85CfU1tZy3nnnMXjwYIYPH843v/lNrrvuOsaMGcNxxx3XXF9XkiS1RkVlULSbkLd+eSbETc22956HifdkrykoievhdRsKFT2guDLTKmIr2brf4Hhhqc/YSSlpimfa9gcKQwjPARXAr5Ik2WmvXGtw/vnn88ADD7BgwQLGjh3LnXfeyeLFixk/fjyFhYX079+furq6vfrMJEl2evxTn/oURx55JI899hinnXYat956K6NHj2b8+PE8/vjj/Pu//zunnnoq3/ve95riq0mSpPagtBP0PTK2hupWZnvkFr8Tw9zsf8Uhl5vX7/lz8wqyoW5rmCupyqyZ1xPKu0NFz/iM3dZWWNI831FqZ5oitBUAhwEnA6XAv0IILydJMm37C0MIVwBXAPTt28ghAC1s7NixfOELX2DJkiX84x//4L777qN79+4UFhby7LPP8v777+/1Zx5//PHceeedjB49mmnTpjF79mwOOOAAZs6cycCBA/nqV7/KzJkzmThxIkOGDKFz5858+tOfpry8nNtvsJ6sxgAADZVJREFUv73pv6QkSWp/Sqqgz+GxbW/zRti4Bjasgg2roS6z3bAaNqzM7m9zfBWsrIW54zNr1e3kH6lLqrYNcRWZcLc15FX2ipOoFJc3+9eXWrOmCG21xMlH1gJrQwjPAwcDO4S2JEluAW4BGDVq1M67n1J24IEHsnr1ampqaqiurubiiy/mYx/7GKNGjWLkyJEMGTJkrz/zyiuv5Itf/CLDhw+noKCA22+/neLiYu69917uuOMOCgsL6dmzJ9/73vd47bXX+Na3vkVeXh6FhYXcdNNNzfAtJUmSGigogoLOH37tuPrN8Tm7NQth9cK4XbMA1iyC1Znt3HHx3M569Uqq4hIIVTUxxFXVbPu6ssZeO7VrYVdD97a5KD7T9ujOZo8MIQwlTlRyGlAEvAqMTZJktwuUjRo1Khk3btw2x6ZMmcLQoUMbW7v2wD9PSZKUU5Ik9tKtWRRD3ap5sbdu1VxYOTdOqrJyLqxftuN7y7pCVe/YPgh2NZnXvaCiGvILW/47SfsghDA+SZJRe7quMVP+3w2cCHQNIdQC3ydO7U+SJDcnSTIlhPAEMBHYAty6p8AmSZKkdiiEOMlJSSV03W/X121cFwPd1hC3am423C19N06ssmG7paFCXnbNuu176rYGvfIeLoGgVqkxs0d+shHX/Az4WZNU1MpMmjSJSy65ZJtjxcXFvPLKKylVJEmS1MoVlcVQt7tgV7cy01M3d8dwt/AtmPa3HYdi5hVARa8Y5sq6QFE5FHWIrbgiu19Uvu25ovL43F1Rh7gmXn5TPGEkNZ533D4aPnw4EyZMSLsMSZKk9qWkKrbuu3gUJEni8gcfDL9sOAxzLix7Dzauho1rY9u8F7ODF5bFnruOfaFjH6jqE9e+69gnHivvaY+empShTZIkSW1PCHFilbLOUD1iz9fXb44zaG4NcRvX7OT1WtiwJvbyrZwT2/w34yQsDeUVxiGZHftAVd9suOvYNwa8yhp767RXvFskSZKk/AIo7Rjb3tq4NvbkrZgd28o5mf058O7TsHr+ttfnFULnAdBlMHQZFBc677JffN2hq4uYaweGNkmSJGlfFHWAbgfEtjObN2RD3co5sGwmLJ0BS2bAjKegfmP22pKqbIDrknmur8tg6DwwPuundsnQJkmSJDWnguLYo9Zl0I7nttTHILdkRgxyS6fDkukw6wWYeM+211b1gU7948QoBUWQXwz5Rdn9gqL4epv9ovjz84vjkgglldnFzks7++xdK2Foa2DFihXcddddXHnllXv1vjPPPJO77rqLjh33rjv9sssuY8yYMZx//vl79T5JkiS1EXn5MYh16g+DT9n23Ma1sVduyfRMoJsRJ1BZvyL2ztVvgM0bM/sbY49e/YbG/+yQD+XdsyFu635FzwbHu8eJVezlS5WhrYEVK1Zw44037hDa6uvryc/P3+X7Hn/88eYuTZIkSe1NUQfoOTy2xkoS2LI5E+AahrnMdsMqWLMws8D5Qli9MLOdHydVWbsIki07qaUiBrgO3eJzdx26NWjbvS7tZA9eE8vd0PbXb8OCSU37mT2Hwxk/3eXpb3/727z77ruMHDmSwsJCysvLqa6uZsKECbz99tuce+65zJkzh7q6Oq6++mquuOIKAPr378+4ceNYs2YNZ5xxBsceeywvvfQSNTU1/PnPf6a0tHSPpT399NN885vfZPPmzRx++OHcdNNNFBcX8+1vf5tHHnmEgoICTj31VH7+859z//3388Mf/pD8/Hyqqqp4/vnnm+yPSJIkSa1YCHEYZH7hh3v/lnpYtzQT7BqEuzWLYPWCOFPmspkw55V43c4CXsiP6+BtH+jKuzXoyesZtw7RbJTcDW0p+OlPf8rkyZOZMGECzz33HGeddRaTJ09mwIABANx222107tyZ9evXc/jhh/OJT3yCLl26bPMZ06dP5+677+Y3v/kNF154IQ8++CCf/vSnd/tz6+rquOyyy3j66afZf//9ufTSS7npppu49NJLefjhh5k6dSohBFasWAHAj370I5588klqamo+OCZJkiTts7ytQya7A3vo4dtSH9fCW7u4QVuy4/681+P+hlU7+XkF2eGZFT13ve3QvV0vk5C733w3PWIt5YgjjvggsAFcf/31PPzwwwDMmTOH6dOn7xDaBgwYwMiRIwE47LDDmDVr1h5/zjvvvMOAAQPYf//9AfjMZz7DDTfcwFe+8hVKSkr4/Oc/z1lnncWYMWMAOOaYY7jsssu48MILOe+885riq0qSJEl7Jy8/05PWFdjFIucNbVofe+vWLNz5dsVsmPPqjuveARBigKusjuvcVfaKraJXdr+yFxTueYRba5S7oS0HdOjQ4YP95557jr///e/861//oqysjBNPPJG6urod3lNcXPzBfn5+PuvXr9/jz0mSZKfHCwoKePXVV3n66ae55557+PWvf80zzzzDzTffzCuvvMJjjz3GyJEjmTBhwg7hUZIkScophaVxfbrOA3Z/3eaN8dm61QthzYJssFs1L7al78Ksf8ZFzrdX2mnbUFdZAxXVcbHzQSc1z/dqAYa2BioqKli9evVOz61cuZJOnTpRVlbG1KlTefnll5vs5w4ZMoRZs2YxY8YM9ttvP/74xz9ywgknsGbNGtatW8eZZ57JUUcdxX777QfAu+++y5FHHsmRRx7JX/7yF+bMmWNokyRJUttQUBRDVlXv3V+3YU2cQGXVXFi1dZsJdqvmwrw34vBMiL1035zW/LU3E0NbA126dOGYY47hoIMOorS0lB49enxw7vTTT+fmm29mxIgRHHDAARx11FFN9nNLSkr43e9+xwUXXPDBRCRf/OIXWbZsGeeccw51dXUkScIvf/lLAL71rW8xffp0kiTh5JNP5uCDD26yWiRJkqRWobgcigdD18G7vmbzhhjsdtYr14qEXQ3Na26jRo1Kxo0bt82xKVOmMHRoI8bDqlH885QkSZJyVwhhfJIko/Z0nfNrSpIkSVIOc3hkC/jyl7/Miy++uM2xq6++mssvvzyliiRJkiS1Foa2FnDDDTekXYIkSZKkVirnhkem9YxdW+OfoyRJktQ25FRoKykpYenSpQaOfZQkCUuXLqWkpCTtUiRJkiTto5waHtm7d29qa2tZvHhx2qW0eiUlJfTuvYe1LSRJkiTlvJwKbYWFhQwYsIcV0iVJkiSpHcmp4ZGSJEmSpG0Z2iRJkiQphxnaJEmSJCmHhbRmagwhLAbeT+WH715XYEnaRajd8H5TS/FeU0vxXlNL8V5TS2qu+61fkiTd9nRRaqEtV4UQxiVJMirtOtQ+eL+ppXivqaV4r6mleK+pJaV9vzk8UpIkSZJymKFNkiRJknKYoW1Ht6RdgNoV7ze1FO81tRTvNbUU7zW1pFTvN59pkyRJkqQcZk+bJEmSJOUwQ1sDIYTTQwjvhBBmhBC+nXY9ajtCCLeFEBaFECY3ONY5hPBUCGF6ZtspzRrVNoQQ+oQQng0hTAkhvBVCuDpz3PtNTS6EUBJCeDWE8Gbmfvth5viAEMIrmfvt3hBCUdq1qm0IIeSHEN4IITyaee29piYXQpgVQpgUQpgQQhiXOZbq71FDW0YIIR+4ATgDGAZ8MoQwLN2q1IbcDpy+3bFvA08nSTIYeDrzWtpXm4FvJEkyFDgK+HLm/2Xeb2oOG4DRSZIcDIwETg8hHAX8F/DLzP22HPhcijWqbbkamNLgtfeamstJSZKMbDDNf6q/Rw1tWUcAM5IkmZkkyUbgHuCclGtSG5EkyfPAsu0OnwP8PrP/e+DcFi1KbVKSJPOTJHk9s7+a+JebGrzf1AySaE3mZWGmJcBo4IHMce83NYkQQm/gLODWzOuA95paTqq/Rw1tWTXAnAavazPHpObSI0mS+RD/og10T7ketTEhhP7AIcAreL+pmWSGq00AFgFPAe8CK5Ik2Zy5xN+nair/DVwLbMm87oL3mppHAvwthDA+hHBF5liqv0cLWvKH5biwk2NOrSmpVQohlAMPAtckSbIq/oO01PSSJKkHRoYQOgIPA0N3dlnLVqW2JoQwBliUJMn4EMKJWw/v5FLvNTWFY5IkmRdC6A48FUKYmnZB9rRl1QJ9GrzuDcxLqRa1DwtDCNUAme2ilOtRGxFCKCQGtjuTJHkoc9j7Tc0qSZIVwHPEZyk7hhC2/sOwv0/VFI4Bzg4hzCI+wjKa2PPmvaYmlyTJvMx2EfEfo44g5d+jhras14DBmVmIioCxwCMp16S27RHgM5n9zwB/TrEWtRGZZzx+C0xJkuQXDU55v6nJhRC6ZXrYCCGUAqcQn6N8Fjg/c5n3m/ZZkiT/niRJ7yRJ+hP/jvZMkiQX472mJhZC6BBCqNi6D5wKTCbl36Murt1ACOFM4r/a5AO3JUnyk5RLUhsRQrgbOBHoCiwEvg/8CbgP6AvMBi5IkmT7yUqkvRJCOBb4JzCJ7HMf/0F8rs37TU0qhDCC+EB+PvEfgu9LkuRHIYSBxN6QzsAbwKeTJNmQXqVqSzLDI7+ZJMkY7zU1tcw99XDmZQFwV5IkPwkhdCHF36OGNkmSJEnKYQ6PlCRJkqQcZmiTJEmSpBxmaJMkSZKkHGZokyRJkqQcZmiTJEmSpBxmaJMkSZKkHGZokyRJkqQcZmiTJEmSpBz2/wAVQEAv03PcVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['val_loss'], '-', label = 'val_loss' )\n",
    "plt.plot(model.history.history['loss'], '-', label = 'train_loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a simpler model with no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dense():\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    shop_id_in = Input((1,), name = 'shop_id_in')\n",
    "    shop_id = Embedding(60,10)(shop_id_in)\n",
    "    shop_id = Reshape((10,))(shop_id)\n",
    "    layers.append(shop_id)\n",
    "    \n",
    "    itcat_id_in = Input((1,), name='itcat_in')\n",
    "    itcat_id = Embedding(84,12)(itcat_id_in)\n",
    "    itcat_id = Reshape((12,))(itcat_id)\n",
    "    layers.append(itcat_id)\n",
    "    \n",
    "    month_in = Input((1,), name='month_in')\n",
    "    month = Embedding(12,4)(month_in)\n",
    "    month = Reshape((4,))(month)\n",
    "    layers.append(month)\n",
    "    \n",
    "    year_in = Input((1,), name='year_in')\n",
    "    year = Embedding(3,2)(year_in)\n",
    "    year = Reshape((2,))(year)\n",
    "    layers.append(year)\n",
    "    \n",
    "    date_block_in = Input((1,), name='date_block_in')\n",
    "    date_block = Dense(1)(date_block_in)\n",
    "    layers.append(date_block)\n",
    "    \n",
    "    shop_id_enc_in = Input((4,), name='shop_id_end_in')\n",
    "    shop_id_enc = Dense(4)(shop_id_enc_in)\n",
    "    layers.append(shop_id_enc)\n",
    "    \n",
    "    item_id_enc_in = Input((4,), name='item_id_end_in')\n",
    "    item_id_enc = Dense(4)(item_id_enc_in)\n",
    "    layers.append(item_id_enc)\n",
    "    \n",
    "    itcat_id_enc_in = Input((4,), name='itcat_id_end_in')\n",
    "    itcat_id_enc = Dense(4)(itcat_id_enc_in)\n",
    "    layers.append(itcat_id_enc)\n",
    "    \n",
    "    month_id_enc_in = Input((4,), name='month_id_end_in')\n",
    "    month_id_enc = Dense(4)(month_id_enc_in)\n",
    "    layers.append(month_id_enc)\n",
    "    \n",
    "    year_id_enc_in = Input((4,), name='year_id_end_in')\n",
    "    year_id_enc = Dense(4)(year_id_enc_in)\n",
    "    layers.append(year_id_enc)\n",
    "    \n",
    "    shop_item_lag_in = Input((11,), name='shop_item_lag_in')\n",
    "    shop_item_lag = Dense(11)(shop_item_lag_in)\n",
    "    layers.append(shop_item_lag)\n",
    "    \n",
    "    shop_lag_in = Input((11,), name='shop_lag_in')\n",
    "    shop_lag = Dense(11)(shop_lag_in)\n",
    "    layers.append(shop_lag)\n",
    "    \n",
    "    item_lag_in = Input((11,), name='item_lag_in')\n",
    "    item_lag = Dense(11)(item_lag_in)\n",
    "    layers.append(item_lag)\n",
    "    \n",
    "    itcat_lag_in = Input((11,), name='itcat_lag_in')\n",
    "    itcat_lag = Dense(11)(itcat_lag_in)\n",
    "    layers.append(itcat_lag)\n",
    "    \n",
    "    item_name_in = Input((5,),name='item_name_in')\n",
    "    item_name = Dense(5)(item_name_in)\n",
    "    layers.append(item_name)\n",
    "    \n",
    "    itcat_name_in = Input((5,), name='itcat_name_in')\n",
    "    itcat_name = Dense(5)(itcat_name_in)\n",
    "    layers.append(itcat_name)\n",
    "    \n",
    "    model = Concatenate()(layers)\n",
    "    model = Dropout(0.02)(model)\n",
    "    model = Dense(1000, activation='relu',name='fc1')(model)\n",
    "    model = Dense(500, activation='relu', name='fc2')(model)\n",
    "    #model = Dropout(0.2)(model)\n",
    "    \n",
    "    #model = Dense(150,activation='relu', name='fc3')(model)\n",
    "    #model = Dropout(0.1)(model)\n",
    "    \n",
    "    #model = Dense(15, activation='relu',name='fc4')(model)\n",
    "    model= Dense(1,name='fc5')(model)\n",
    "    \n",
    "    final_model = Model(inputs = [shop_id_in, itcat_id_in, month_in, year_in, date_block_in, shop_id_enc_in,\n",
    "                                 item_id_enc_in, itcat_id_enc_in, month_id_enc_in, year_id_enc_in, shop_item_lag_in,\n",
    "                                 shop_lag_in, item_lag_in, itcat_lag_in, item_name_in, itcat_name_in],\n",
    "                       outputs = model,\n",
    "                       name = 'nn_enc_dense_pfs4')\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "shop_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_54 (Embedding)        (None, 1, 10)        600         shop_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_55 (Embedding)        (None, 1, 12)        1008        itcat_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_56 (Embedding)        (None, 1, 4)         48          month_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_57 (Embedding)        (None, 1, 2)         6           year_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "date_block_in (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_item_lag_in (InputLayer)   (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_lag_in (InputLayer)       (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_name_in (InputLayer)       (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_name_in (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)            (None, 10)           0           embedding_54[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)            (None, 12)           0           embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 4)            0           embedding_56[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 2)            0           embedding_57[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 1)            2           date_block_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 4)            20          shop_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 4)            20          item_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 4)            20          itcat_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 4)            20          month_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 4)            20          year_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 11)           132         shop_item_lag_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 11)           132         shop_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 11)           132         item_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 11)           132         itcat_lag_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 5)            30          item_name_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 5)            30          itcat_name_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 103)          0           reshape_54[0][0]                 \n",
      "                                                                 reshape_55[0][0]                 \n",
      "                                                                 reshape_56[0][0]                 \n",
      "                                                                 reshape_57[0][0]                 \n",
      "                                                                 dense_137[0][0]                  \n",
      "                                                                 dense_138[0][0]                  \n",
      "                                                                 dense_139[0][0]                  \n",
      "                                                                 dense_140[0][0]                  \n",
      "                                                                 dense_141[0][0]                  \n",
      "                                                                 dense_142[0][0]                  \n",
      "                                                                 dense_143[0][0]                  \n",
      "                                                                 dense_144[0][0]                  \n",
      "                                                                 dense_145[0][0]                  \n",
      "                                                                 dense_146[0][0]                  \n",
      "                                                                 dense_147[0][0]                  \n",
      "                                                                 dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 103)          0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1000)         104000      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 500)          500500      fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 1)            501         fc2[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 607,353\n",
      "Trainable params: 607,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model_dense()\n",
    "model.compile('Adam', loss = 'mean_squared_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/50\n",
      "1483908/1483908 [==============================] - 78s 53us/step - loss: 2.8510 - val_loss: 2.9745\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.97454, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 2/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 2.3736 - val_loss: 2.7426\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.97454 to 2.74261, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 3/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 2.2696 - val_loss: 2.6175\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.74261 to 2.61748, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 4/50\n",
      "1483908/1483908 [==============================] - 75s 51us/step - loss: 2.2002 - val_loss: 2.6246\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.61748\n",
      "Epoch 5/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 2.1431 - val_loss: 2.4924\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.61748 to 2.49237, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 6/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 2.0916 - val_loss: 2.5530\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.49237\n",
      "Epoch 7/50\n",
      "1483908/1483908 [==============================] - 75s 51us/step - loss: 2.0543 - val_loss: 2.4562\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.49237 to 2.45623, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 8/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 2.0151 - val_loss: 2.4651\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.45623\n",
      "Epoch 9/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.9838 - val_loss: 2.4059\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.45623 to 2.40590, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 10/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.9460 - val_loss: 2.4351\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.40590\n",
      "Epoch 11/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.9162 - val_loss: 2.4017\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.40590 to 2.40168, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 12/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.8871 - val_loss: 2.4446\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.40168\n",
      "Epoch 13/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.8569 - val_loss: 2.4347\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.40168\n",
      "Epoch 14/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.8359 - val_loss: 2.4379\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.40168\n",
      "Epoch 15/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.8074 - val_loss: 2.4245\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.40168\n",
      "Epoch 16/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.7742 - val_loss: 2.3632\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.40168 to 2.36323, saving model to nn_enc_model_dense_simple_wo_item_pfs4.hdf5\n",
      "Epoch 17/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.7524 - val_loss: 2.4341\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.36323\n",
      "Epoch 18/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.7232 - val_loss: 2.3640\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.36323\n",
      "Epoch 19/50\n",
      "1483908/1483908 [==============================] - 76s 52us/step - loss: 1.7017 - val_loss: 2.5281\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.36323\n",
      "Epoch 20/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.6802 - val_loss: 2.3867\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.36323\n",
      "Epoch 21/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.6570 - val_loss: 2.5901\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.36323\n",
      "Epoch 22/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.6296 - val_loss: 2.5506\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.36323\n",
      "Epoch 23/50\n",
      "1483908/1483908 [==============================] - 76s 52us/step - loss: 1.6066 - val_loss: 2.3992\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.36323\n",
      "Epoch 24/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.5905 - val_loss: 2.4887\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.36323\n",
      "Epoch 25/50\n",
      "1483908/1483908 [==============================] - 78s 53us/step - loss: 1.5673 - val_loss: 2.4171\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.36323\n",
      "Epoch 26/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.5472 - val_loss: 2.5515\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.36323\n",
      "Epoch 27/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.5286 - val_loss: 2.5171\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.36323\n",
      "Epoch 28/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.5038 - val_loss: 2.5711\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.36323\n",
      "Epoch 29/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.4873 - val_loss: 2.5507\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.36323\n",
      "Epoch 30/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.4686 - val_loss: 2.5942\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.36323\n",
      "Epoch 31/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.4487 - val_loss: 2.5100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.36323\n",
      "Epoch 32/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.4332 - val_loss: 2.5155\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.36323\n",
      "Epoch 33/50\n",
      "1483908/1483908 [==============================] - 76s 52us/step - loss: 1.4156 - val_loss: 2.5198\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.36323\n",
      "Epoch 34/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.3987 - val_loss: 2.5407\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.36323\n",
      "Epoch 35/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.3870 - val_loss: 2.6643\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.36323\n",
      "Epoch 36/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.3731 - val_loss: 2.6057\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.36323\n",
      "Epoch 37/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.3586 - val_loss: 2.5395\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.36323\n",
      "Epoch 38/50\n",
      "1483908/1483908 [==============================] - 76s 52us/step - loss: 1.3440 - val_loss: 2.6480\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.36323\n",
      "Epoch 39/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.3296 - val_loss: 2.5764\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.36323\n",
      "Epoch 40/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.3150 - val_loss: 2.6109\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.36323\n",
      "Epoch 41/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.2985 - val_loss: 2.6020\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.36323\n",
      "Epoch 42/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.2958 - val_loss: 2.6203\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.36323\n",
      "Epoch 43/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.2784 - val_loss: 2.6235\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.36323\n",
      "Epoch 44/50\n",
      "1483908/1483908 [==============================] - 76s 52us/step - loss: 1.2660 - val_loss: 2.6019\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.36323\n",
      "Epoch 45/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.2523 - val_loss: 2.6762\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.36323\n",
      "Epoch 46/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.2462 - val_loss: 2.7372\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.36323\n",
      "Epoch 47/50\n",
      "1483908/1483908 [==============================] - 77s 52us/step - loss: 1.2338 - val_loss: 2.6362\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.36323\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483908/1483908 [==============================] - 75s 51us/step - loss: 1.2249 - val_loss: 2.6880\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.36323\n",
      "Epoch 49/50\n",
      "1483908/1483908 [==============================] - 75s 51us/step - loss: 1.2164 - val_loss: 2.6527\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.36323\n",
      "Epoch 50/50\n",
      "1483908/1483908 [==============================] - 76s 51us/step - loss: 1.2055 - val_loss: 2.6111\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.36323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd7123c1d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss', patience = 15)\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_simple_wo_item_pfs4.hdf5', monitor='val_loss', verbose=1, \n",
    "                              save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=2048, epochs=50, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Learning Curve')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['val_loss'], '-', label = 'val_loss' )\n",
    "plt.plot(model.history.history['loss'], '-', label = 'train_loss')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dense():\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    shop_id_in = Input((1,), name = 'shop_id_in')\n",
    "    shop_id = Embedding(60,10)(shop_id_in)\n",
    "    shop_id = Reshape((10,))(shop_id)\n",
    "    layers.append(shop_id)\n",
    "    \n",
    "    itcat_id_in = Input((1,), name='itcat_in')\n",
    "    itcat_id = Embedding(84,12)(itcat_id_in)\n",
    "    itcat_id = Reshape((12,))(itcat_id)\n",
    "    layers.append(itcat_id)\n",
    "    \n",
    "    month_in = Input((1,), name='month_in')\n",
    "    month = Embedding(12,4)(month_in)\n",
    "    month = Reshape((4,))(month)\n",
    "    layers.append(month)\n",
    "    \n",
    "    year_in = Input((1,), name='year_in')\n",
    "    year = Embedding(3,2)(year_in)\n",
    "    year = Reshape((2,))(year)\n",
    "    layers.append(year)\n",
    "    \n",
    "    date_block_in = Input((1,), name='date_block_in')\n",
    "    date_block = Dense(1)(date_block_in)\n",
    "    layers.append(date_block)\n",
    "    \n",
    "    shop_id_enc_in = Input((4,), name='shop_id_end_in')\n",
    "    shop_id_enc = Dense(4)(shop_id_enc_in)\n",
    "    layers.append(shop_id_enc)\n",
    "    \n",
    "    item_id_enc_in = Input((4,), name='item_id_end_in')\n",
    "    item_id_enc = Dense(4)(item_id_enc_in)\n",
    "    layers.append(item_id_enc)\n",
    "    \n",
    "    itcat_id_enc_in = Input((4,), name='itcat_id_end_in')\n",
    "    itcat_id_enc = Dense(4)(itcat_id_enc_in)\n",
    "    layers.append(itcat_id_enc)\n",
    "    \n",
    "    month_id_enc_in = Input((4,), name='month_id_end_in')\n",
    "    month_id_enc = Dense(4)(month_id_enc_in)\n",
    "    layers.append(month_id_enc)\n",
    "    \n",
    "    year_id_enc_in = Input((4,), name='year_id_end_in')\n",
    "    year_id_enc = Dense(4)(year_id_enc_in)\n",
    "    layers.append(year_id_enc)\n",
    "    \n",
    "    shop_item_lag_in = Input((11,), name='shop_item_lag_in')\n",
    "    shop_item_lag = Dense(11)(shop_item_lag_in)\n",
    "    layers.append(shop_item_lag)\n",
    "    \n",
    "    shop_lag_in = Input((11,), name='shop_lag_in')\n",
    "    shop_lag = Dense(11)(shop_lag_in)\n",
    "    layers.append(shop_lag)\n",
    "    \n",
    "    item_lag_in = Input((11,), name='item_lag_in')\n",
    "    item_lag = Dense(11)(item_lag_in)\n",
    "    layers.append(item_lag)\n",
    "    \n",
    "    itcat_lag_in = Input((11,), name='itcat_lag_in')\n",
    "    itcat_lag = Dense(11)(itcat_lag_in)\n",
    "    layers.append(itcat_lag)\n",
    "    \n",
    "    item_name_in = Input((5,),name='item_name_in')\n",
    "    item_name = Dense(5)(item_name_in)\n",
    "    layers.append(item_name)\n",
    "    \n",
    "    itcat_name_in = Input((5,), name='itcat_name_in')\n",
    "    itcat_name = Dense(5)(itcat_name_in)\n",
    "    layers.append(itcat_name)\n",
    "    \n",
    "    model = Concatenate()(layers)\n",
    "    model = Dropout(0.02)(model)\n",
    "    model = Dense(1000, activation='relu',name='fc1')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dense(500, activation='relu', name='fc2')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    #model = Dropout(0.2)(model)\n",
    "    \n",
    "    #model = Dense(150,activation='relu', name='fc3')(model)\n",
    "    #model = Dropout(0.1)(model)\n",
    "    \n",
    "    #model = Dense(15, activation='relu',name='fc4')(model)\n",
    "    model= Dense(1,name='fc5')(model)\n",
    "    \n",
    "    final_model = Model(inputs = [shop_id_in, itcat_id_in, month_in, year_in, date_block_in, shop_id_enc_in,\n",
    "                                 item_id_enc_in, itcat_id_enc_in, month_id_enc_in, year_id_enc_in, shop_item_lag_in,\n",
    "                                 shop_lag_in, item_lag_in, itcat_lag_in, item_name_in, itcat_name_in],\n",
    "                       outputs = model,\n",
    "                       name = 'nn_enc_dense_pfs4')\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "shop_id_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_in (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_58 (Embedding)        (None, 1, 10)        600         shop_id_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_59 (Embedding)        (None, 1, 12)        1008        itcat_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, 1, 4)         48          month_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, 1, 2)         6           year_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "date_block_in (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_id_end_in (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_id_end_in (InputLayer)     (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_item_lag_in (InputLayer)   (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shop_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lag_in (InputLayer)        (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_lag_in (InputLayer)       (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_name_in (InputLayer)       (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "itcat_name_in (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_58 (Reshape)            (None, 10)           0           embedding_58[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_59 (Reshape)            (None, 12)           0           embedding_59[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_60 (Reshape)            (None, 4)            0           embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_61 (Reshape)            (None, 2)            0           embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 1)            2           date_block_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 4)            20          shop_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 4)            20          item_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 4)            20          itcat_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 4)            20          month_id_end_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 4)            20          year_id_end_in[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 11)           132         shop_item_lag_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 11)           132         shop_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 11)           132         item_lag_in[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 11)           132         itcat_lag_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 5)            30          item_name_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 5)            30          itcat_name_in[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 103)          0           reshape_58[0][0]                 \n",
      "                                                                 reshape_59[0][0]                 \n",
      "                                                                 reshape_60[0][0]                 \n",
      "                                                                 reshape_61[0][0]                 \n",
      "                                                                 dense_149[0][0]                  \n",
      "                                                                 dense_150[0][0]                  \n",
      "                                                                 dense_151[0][0]                  \n",
      "                                                                 dense_152[0][0]                  \n",
      "                                                                 dense_153[0][0]                  \n",
      "                                                                 dense_154[0][0]                  \n",
      "                                                                 dense_155[0][0]                  \n",
      "                                                                 dense_156[0][0]                  \n",
      "                                                                 dense_157[0][0]                  \n",
      "                                                                 dense_158[0][0]                  \n",
      "                                                                 dense_159[0][0]                  \n",
      "                                                                 dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 103)          0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1000)         104000      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000)         4000        fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 500)          500500      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 1)            501         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 613,353\n",
      "Trainable params: 610,353\n",
      "Non-trainable params: 3,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model_dense()\n",
    "model.compile('Adam', loss = 'mean_squared_error')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483908 samples, validate on 59742 samples\n",
      "Epoch 1/50\n",
      "1483908/1483908 [==============================] - 128s 86us/step - loss: 2.9079 - val_loss: 2.7281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.72814, saving model to nn_enc_model_dense_simple_bn_wo_item_pfs4.hdf5\n",
      "Epoch 2/50\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 2.3333 - val_loss: 2.6653\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.72814 to 2.66527, saving model to nn_enc_model_dense_simple_bn_wo_item_pfs4.hdf5\n",
      "Epoch 3/50\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 2.2331 - val_loss: 2.3795\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.66527 to 2.37945, saving model to nn_enc_model_dense_simple_bn_wo_item_pfs4.hdf5\n",
      "Epoch 4/50\n",
      "1483908/1483908 [==============================] - 124s 84us/step - loss: 2.1743 - val_loss: 2.4331\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.37945\n",
      "Epoch 5/50\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 2.1177 - val_loss: 2.4334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.37945\n",
      "Epoch 6/50\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 2.0769 - val_loss: 2.4473\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.37945\n",
      "Epoch 7/50\n",
      "1483908/1483908 [==============================] - 126s 85us/step - loss: 2.0431 - val_loss: 2.4219\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.37945\n",
      "Epoch 8/50\n",
      "1483908/1483908 [==============================] - 125s 84us/step - loss: 2.0119 - val_loss: 2.4276\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.37945\n",
      "Epoch 9/50\n",
      "1396736/1483908 [===========================>..] - ETA: 7s - loss: 1.9783"
     ]
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss', patience = 15)\n",
    "check_point = ModelCheckpoint('nn_enc_model_dense_simple_bn_wo_item_pfs4.hdf5', monitor='val_loss', verbose=1, \n",
    "                              save_best_only=True)\n",
    "model.fit(x = nn_dict['train'], y = nn_dict['train_y'], batch_size=2048, epochs=50, \n",
    "          validation_data=(nn_dict['val'], nn_dict['val_y']), callbacks = [check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
